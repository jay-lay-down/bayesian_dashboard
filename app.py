# -*- coding: utf-8 -*-

# app.py â€” Bayesian Journey Dashboard (Colab-friendly, robust Excel + plots)
# Fixes:
#  - âœ… ì •ê·œí™” ìœ í‹¸(_as_all, _ensure_key_cols ë“±) í¬í•¨
#  - âœ… pick_row_for í¬í•¨
#  - âœ… Plotly ì¶• ê·¸ë¦¬ë“œ ì†ì„± ì •ë¦¬(ìœ íš¨í•˜ì§€ ì•Šì€ prop ì œê±°)
#  - âœ… í¬íŠ¸ ì¶©ëŒ ì‹œ ìë™ ëŒ€ì²´ í¬íŠ¸ë¡œ ì¬ì‹œë„

import os, json, re, traceback
import numpy as np
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
from dash import Dash, html, dcc, dash_table, Input, Output, State
from dash.dash_table import FormatTemplate
from dash.dash_table.Format import Format, Scheme
import dash  # (NEW) ì¸í„°ë™ì…˜ ë¡œê·¸ìš©

# (íŒŒì¼ ìƒë‹¨ import ê·¼ì²˜ì— ì¶”ê°€)
import io

import hashlib

FLOW_SALT = os.getenv("FLOW_SALT", "phi-v1-2025-01")  # í•„ìš”ì‹œ í™˜ê²½ë³€ìˆ˜ë¡œ ë°”ê¿”ì¹˜ê¸° ê°€ëŠ¥
FLOW_SALT = os.getenv("FLOW_SALT", "phi-v1-2025-01")
FLOW_GLOBAL = True        # Trueë©´ ì „ì—­ ê³ ì •, Falseë©´ í•´ì‹œ ê¸°ë°˜
GLOBAL_K = 11.3

def _flow_scale(seg, mod, loy):
    if FLOW_GLOBAL:
        return GLOBAL_K
    key = f"{seg}|{mod}|{loy}|{FLOW_SALT}"
    h = int(hashlib.sha256(key.encode("utf-8")).hexdigest()[:8], 16)
    return 7.5 + (h % 1100) / 100.0

# ======== ì¸í„°ë™ì…˜ ê³µìš© ì„¤ì • ========
GRAPH_CONFIG = {
    "displayModeBar": True,
    "scrollZoom": True,          # íœ ë¡œ ì¤Œ
    "doubleClick": "reset",      # ë”ë¸”í´ë¦­ ë¦¬ì…‹
    "modeBarButtonsToAdd": ["lasso2d", "select2d"],
    "showTips": True,
}

# ===================== ê¸°ë³¸ ê²½ë¡œ =====================
DEFAULT_PATH = r"/content/drive/MyDrive/baye_dash/bayesian_analysis_total_v1.xlsx"

# ===================== ë ˆë²¨ ìƒìˆ˜ =====================
LEVEL_OVERALL="ì „ì²´"; LEVEL_SEGMENT="ì„¸ê·¸ë¨¼íŠ¸"; LEVEL_MODEL="ëª¨ë¸"
LEVEL_LOYALTY="ì¶©ì„±ë„"; LEVEL_SEG_X_LOY="ì„¸ê·¸Ã—ì¶©ì„±ë„"
LEVEL_SEG_X_MODEL="ì„¸ê·¸Ã—ëª¨ë¸"; LEVEL_MODEL_X_LOY="ëª¨ë¸Ã—ì¶©ì„±ë„"
LEVEL_MOD_X_SEG_X_LOY="ëª¨ë¸Ã—ì„¸ê·¸Ã—ì¶©ì„±ë„"

# === ì •ê·œí™” ===
ALL_ALIASES = {"ALL","all","All","", " ", "  ", "ì „ì²´", "NONE","None","none","nan","NaN", None}
LVL_ALIASES = {
    "ëª¨ë¸ì „ì²´Ã—ì„¸ê·¸Ã—ì¶©ì„±ë„": "ëª¨ë¸Ã—ì„¸ê·¸Ã—ì¶©ì„±ë„",
    "ì„¸ê·¸xëª¨ë¸": "ì„¸ê·¸Ã—ëª¨ë¸",
    "ëª¨ë¸xì¶©ì„±ë„": "ëª¨ë¸Ã—ì¶©ì„±ë„",
    "ì„¸ê·¸xì¶©ì„±ë„": "ì„¸ê·¸Ã—ì¶©ì„±ë„",
}

def _as_all(v) -> str:
    s = "ALL" if v is None else str(v).strip()
    return "ALL" if s in ALL_ALIASES else s

def _ensure_key_cols(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    for c in ["analysis_level","segment","model","loyalty"]:
        if c not in df.columns:
            df[c] = "ALL"
        df[c] = (
            df[c].astype(str).str.strip()
              .replace({
                  "": "ALL", "ì „ì²´":"ALL",
                  "NONE":"ALL","None":"ALL","none":"ALL",
                  "nan":"ALL","NaN":"ALL",
                  "ALL":"ALL","All":"ALL","all":"ALL"
              })
              .fillna("ALL")
        )
    if "level" not in df.columns:
        df["level"] = df["analysis_level"] if "analysis_level" in df.columns else "ì „ì²´"
    df["level"] = (
        df["level"].astype(str).str.strip()
          .replace({"ALL":"ì „ì²´","All":"ì „ì²´","all":"ì „ì²´"})
          .replace(LVL_ALIASES)
    )
    if "analysis_level" in df.columns:
        df["analysis_level"] = df["analysis_level"].replace(LVL_ALIASES)
    return df

# ---- Store JSON ë¡œë” & ìŠ¤ì™‘ ê°ì§€ ìœ í‹¸ ----
def _looks_split_df_json(s: str) -> bool:
    try:
        o = json.loads(s)
        # orient="split"ëŠ” ìµœì†Œ columns/index/data 3ì…‹ì´ ìˆìŒ
        return isinstance(o, dict) and {"columns","index","data"}.issubset(set(o.keys()))
    except Exception:
        return False

def _looks_overall_json(s: str) -> bool:
    try:
        o = json.loads(s)
        return isinstance(o, dict) and any(k in o for k in ("pref_mean","rec_mean","intent_mean","buy_mean"))
    except Exception:
        return False

def _safe_read_df_split(js: str | dict | None) -> pd.DataFrame:
    if js is None:
        return pd.DataFrame()
    if isinstance(js, dict):  # ì´ë¯¸ íŒŒì‹±ëœ ê²½ìš°
        # dictê°€ split ìŠ¤í‚¤ë§ˆì¸ ê²½ìš°ë§Œ ì²˜ë¦¬
        if {"columns","index","data"}.issubset(set(js.keys())):
            return pd.read_json(io.StringIO(json.dumps(js)), orient="split")
        return pd.DataFrame()
    # str
    try:
        return pd.read_json(io.StringIO(js), orient="split")
    except Exception:
        return pd.DataFrame()

def _safe_read_overall(js: str | dict | None) -> dict:
    if js is None:
        return {}
    if isinstance(js, dict):
        return js
    try:
        o = json.loads(js)
        return o if isinstance(o, dict) else {}
    except Exception:
        return {}

def _maybe_swap_sankey_overall(js_sankey, js_overall):
    """
    sankey ìºì‹œì™€ overallì´ ë’¤ë°”ë€Œì–´ ë“¤ì–´ì˜¨ ê²½ìš° ìë™ êµì •.
    (js_sankeyê°€ overall dictì´ê³ , js_overallì´ split DF JSONì¸ ì¼€ì´ìŠ¤)
    """
    try:
        if isinstance(js_sankey, str) and _looks_overall_json(js_sankey) \
           and isinstance(js_overall, str) and _looks_split_df_json(js_overall):
            return js_overall, js_sankey, True  # (êµì •ëœ sankey, overall, swapped?)
    except Exception:
        pass
    return js_sankey, js_overall, False

_read_df_store = _safe_read_df_split
_read_overall  = _safe_read_overall

def _rebuild_hkey_using_level(df: pd.DataFrame) -> pd.DataFrame:
    df = _ensure_key_cols(df).copy()
    if "level" in df.columns and df["level"].notna().any():
        pass
    elif "analysis_level" in df.columns:
        df["level"] = df["analysis_level"]
    else:
        df["level"] = "ì „ì²´"
    for c in ["level","segment","model","loyalty"]:
        if c != "level":
            df[c] = (
                df[c].astype(str).str.strip()
                  .replace({"": "ALL","ì „ì²´":"ALL","NONE":"ALL","None":"ALL","none":"ALL","nan":"ALL","NaN":"ALL"})
                  .fillna("ALL")
            )
    df["level"] = df["level"].replace(LVL_ALIASES)
    df["hierarchy_key"] = df["level"] + "|" + df["segment"] + "|" + df["model"] + "|" + df["loyalty"]
    return df

def sample_col_in_df(df) -> str | None:
    for c in ["pref_sample_size","sample_size","n","N","base","ë² ì´ìŠ¤ìˆ˜","í‘œë³¸ìˆ˜"]:
        if c in df.columns: return c
    return None

# ==== ë¹„ê³µê°œ ìœ ëŸ‰ ìŠ¤ì¼€ì¼ ====
FLOW_GLOBAL = True
GLOBAL_K = 11.3

# ==== ê³µìš©: Shape-safe helpers (ê°€ì§œ í‚¤ ìë™ ì°¨ë‹¨ + ë³´ì •) ====

_ALLOWED_SHAPE_KEYS = {
    "editable","fillcolor","fillrule","label","layer","legend","legendgroup","legendgrouptitle",
    "legendrank","legendwidth","line","name","opacity","path","showlegend","templateitemname",
    "type","visible","x0","x1","xanchor","xref","xsizemode","y0","y1","yanchor","yref","ysizemode",
}

# ì—¬ê¸°ê°€ ë¬¸ì œì˜ ê°€ì§œ í‚¤ë“¤
_SHIFT_KEYS = ("x0shift", "x1shift", "y0shift", "y1shift")

def _line_from_kwargs(kwargs: dict):
    line = {}
    if "line_color" in kwargs: line["color"] = kwargs.pop("line_color")
    if "line_width" in kwargs: line["width"] = kwargs.pop("line_width")
    if "line_dash"  in kwargs: line["dash"]  = kwargs.pop("line_dash")
    return {k: v for k, v in line.items() if v is not None}

def _clean_shape_kwargs(kwargs: dict):
    """
    1) *_shift í‚¤ ì œê±°
    2) line_* â†’ line ë³‘í•©
    3) í—ˆìš© í‚¤ë§Œ ë‚¨ê¸°ê¸°
    """
    kwargs = dict(kwargs)  # shallow copy
    # 1) ê°€ì§œ shift í‚¤ ëª¨ë‘ ì œê±°
    for k in _SHIFT_KEYS:
        kwargs.pop(k, None)
    # 2) line_* â†’ line ë³‘í•©
    line = _line_from_kwargs(kwargs)
    if line:
        base_line = kwargs.get("line") or {}
        kwargs["line"] = {**base_line, **line}
    # 3) í—ˆìš© í‚¤ë§Œ í†µê³¼
    return {k: v for k, v in kwargs.items() if (k in _ALLOWED_SHAPE_KEYS and v is not None)}

def add_vline_safe(fig, x, **kwargs):
    """ì„¸ë¡œ ê¸°ì¤€ì„ (ê°€ì§œ í‚¤ ì°¨ë‹¨, line_* ë³‘í•©)"""
    base = dict(
        type="line", xref="x", x0=float(x), x1=float(x),
        yref="paper", y0=0, y1=1,
        layer=kwargs.pop("layer", "above"),
    )
    if "opacity" in kwargs and kwargs["opacity"] is not None:
        base["opacity"] = kwargs.pop("opacity")
    base.update(_clean_shape_kwargs(kwargs))
    return fig.add_shape(**base)

def add_hline_safe(fig, y, **kwargs):
    """ê°€ë¡œ ê¸°ì¤€ì„ (ê°€ì§œ í‚¤ ì°¨ë‹¨, line_* ë³‘í•©)"""
    base = dict(
        type="line", yref="y", y0=float(y), y1=float(y),
        xref="paper", x0=0, x1=1,
        layer=kwargs.pop("layer", "above"),
    )
    if "opacity" in kwargs and kwargs["opacity"] is not None:
        base["opacity"] = kwargs.pop("opacity")
    base.update(_clean_shape_kwargs(kwargs))
    return fig.add_shape(**base)

def add_vrect_safe(fig, x0, x1, **kwargs):
    """
    add_vrect ëŒ€ì²´: x0shift/x1shiftë¥¼ ê°’ì— ë°˜ì˜ í›„ ì œê±°í•˜ê³ ,
    ë‚˜ë¨¸ì§€ í‚¤ëŠ” ì•ˆì „í•˜ê²Œ ì •ë¦¬í•´ì„œ rect shapeë¡œ ì¶”ê°€.
    """
    # â”€â”€ shift ë³´ì • â”€â”€
    dx0 = float(kwargs.pop("x0shift", 0) or 0)
    dx1 = float(kwargs.pop("x1shift", 0) or 0)
    x0 = float(x0) + dx0
    x1 = float(x1) + dx1

    # yref ìë™ íŒì •(ëª…ì‹œê°€ ìˆìœ¼ë©´ ì¡´ì¤‘)
    yref = kwargs.pop("yref", None)
    has_y = ("y0" in kwargs) or ("y1" in kwargs)
    if yref is None:
        yref = "y" if has_y else "paper"

    # paper ì¢Œí‘œ ê¸°ë³¸ê°’
    y0_default, y1_default = (0, 1) if yref == "paper" else (None, None)

    base = dict(
        type="rect", xref="x", x0=x0, x1=x1,
        yref=yref, y0=kwargs.pop("y0", y0_default), y1=kwargs.pop("y1", y1_default),
        layer=kwargs.pop("layer", "below"),
        fillcolor=kwargs.pop("fillcolor", "rgba(0,0,0,0.06)"),
    )
    if base["yref"] == "y":
        # ë°ì´í„° ì¶•ì´ë©´ Noneì¸ y0/y1 ì œê±°
        if base.get("y0") is None: base.pop("y0", None)
        if base.get("y1") is None: base.pop("y1", None)

    if "opacity" in kwargs and kwargs["opacity"] is not None:
        base["opacity"] = kwargs.pop("opacity")

    base.update(_clean_shape_kwargs(kwargs))
    return fig.add_shape(**base)

# (ì„ íƒ) ë§Œì•½ ì–´ë”˜ê°€ì—ì„œ layout.shapesì— ì§ì ‘ dictë¥¼ ë„£ëŠ”ë‹¤ë©´:
def sanitize_shape_dict(d: dict) -> dict:
    """ì™¸ë¶€/ë ˆê±°ì‹œ shape dictì„ ì•ˆì „í•˜ê²Œ ì •ì œ.
       - x0shift/x1shift/y0shift/y1shift ê°’ì„ ì¢Œí‘œì— ë°˜ì˜í•˜ê³  í‚¤ ì œê±°
       - line_* í‚¤ ë³‘í•©
       - í—ˆìš©ë˜ì§€ ì•ŠëŠ” í‚¤ ì‚­ì œ
    """
    d = dict(d or {})

    # 1) shift -> ì¢Œí‘œ ë°˜ì˜
    for sh_key, coord_key in (("x0shift","x0"),("x1shift","x1"),("y0shift","y0"),("y1shift","y1")):
        if sh_key in d:
            try:
                if coord_key in d and d[coord_key] is not None:
                    d[coord_key] = float(d[coord_key]) + float(d.pop(sh_key) or 0.0)
                else:
                    d.pop(sh_key, None)
            except Exception:
                d.pop(sh_key, None)

    # 2) line_* -> line ë³‘í•©
    line = {}
    if "line_color" in d: line["color"] = d.pop("line_color")
    if "line_width" in d: line["width"] = d.pop("line_width")
    if "line_dash"  in d: line["dash"]  = d.pop("line_dash")
    if line:
        base_line = d.get("line") or {}
        d["line"] = {**base_line, **{k:v for k,v in line.items() if v is not None}}

    # 3) í—ˆìš© í‚¤ë§Œ ë‚¨ê¸°ê¸°
    return {k: v for k, v in d.items() if (k in _ALLOWED_SHAPE_KEYS and v is not None)}

def _scrub_layout_shapes(fig: go.Figure) -> go.Figure:
    """
    layout.shapesì— ë‚¨ì•„ìˆëŠ” ë¹„ì •ìƒ í‚¤(x0shift ê°™ì€ ì”ì¬)ë¥¼ ì¼ê´„ ì œê±°.
    """
    try:
        shapes = list(fig.layout.shapes) if fig.layout.shapes is not None else []
        cleaned = []
        for sh in shapes:
            try:
                sd = sh.to_plotly_json() if hasattr(sh, "to_plotly_json") else dict(sh)
                cleaned.append(sanitize_shape_dict(sd))  # â† ê¸°ì¡´ ìœ í‹¸ ì¬ì‚¬ìš©
            except Exception:
                # í•˜ë‚˜ë¼ë„ ë¬¸ì œë©´ ê·¸ëƒ¥ ê±´ë„ˆëœ€(ë„ë©´ ê¹¨ì§€ì§€ ì•Šê²Œ)
                continue
        fig.update_layout(shapes=cleaned)
    except Exception:
        pass
    return fig


def sanitize_fig_shapes(fig):
    """fig.layout.shapes ì „ë¶€ sanitize."""
    try:
        shapes = list(fig.layout.shapes) if fig.layout.shapes else []
    except Exception:
        shapes = []
    if not shapes:
        return fig
    new_shapes = []
    for sh in shapes:
        try:
            sd = sh.to_plotly_json() if hasattr(sh, "to_plotly_json") else dict(sh)
            new_shapes.append(sanitize_shape_dict(sd))
        except Exception:
            # ë§ê°€ì§„ ê±´ ë²„ë¦¼
            pass
    fig.update_layout(shapes=new_shapes)
    return fig

# ===================== íŒ”ë ˆíŠ¸ =====================
COL_RED        = "#C32C2C"  # ë¹¨ê°•
COL_ORANGE     = "#D24D3E"  # ì£¼í™©
COL_YELLOW     = "#DE937A"  # ë…¸ë‘
COL_BEIGE      = "#D49442"  # ë² ì´ì§€
COL_GREEN_LITE = "#2B8E81"  # ì´ˆë¡(ê¸°ë³¸)
COL_GREEN_DARK = "#21786E"  # ì´ˆë¡ ì§„í•œí†¤(í•„ìš”ì‹œ)
COL_GRAY       = "#D3D3D3"

def _hex_to_rgb_tuple(h):  # ìœ í‹¸
    h = h.lstrip("#")
    return [int(h[i:i+2], 16) for i in (0,2,4)]

def royg_color_for(values: np.ndarray) -> list:
    v = np.asarray(values, dtype=float)
    if v.size == 0: return []
    if not np.isfinite(v).any():
        return [COL_GREEN_DARK] * len(v)

    lo = np.nanmin(v); hi = np.nanmax(v)
    t = np.zeros_like(v) if (not np.isfinite(lo) or not np.isfinite(hi) or hi-lo < 1e-12) else (v-lo)/(hi-lo)

    # ë‚®ì€ê°’(ì¢‹ìŒ) â†’ ë†’ì€ê°’(ë‚˜ì¨): ì´ˆ â†’ ë²  â†’ ë…¸ â†’ ì£¼ â†’ ë¹¨
    cols = np.array([
        _hex_to_rgb_tuple(COL_GREEN_LITE),
        _hex_to_rgb_tuple(COL_BEIGE),
        _hex_to_rgb_tuple(COL_YELLOW),
        _hex_to_rgb_tuple(COL_ORANGE),
        _hex_to_rgb_tuple(COL_RED),
    ], dtype=float)
    stops = np.array([0.0, 0.25, 0.5, 0.75, 1.0])

    r = np.interp(t, stops, cols[:,0]); g = np.interp(t, stops, cols[:,1]); b = np.interp(t, stops, cols[:,2])
    out = []
    for rr, gg, bb in zip(r,g,b):
        if not (np.isfinite(rr) and np.isfinite(gg) and np.isfinite(bb)):
            out.append('rgb(140,140,140)')
        else:
            out.append(f'rgb({int(round(rr))},{int(round(gg))},{int(round(bb))})')
    return out


# ==== DESIGN CONSTANTS (tiers & neutrals) ====
COL_BLUE_DEEP = "#1E3A8A"   # ì§„íŒŒë‘(í•˜ì´ì—”ë“œ)
COL_BLUE_SKY  = "#60A5FA"   # í•˜ëŠ˜(ë¯¸ë“œ)
COL_GRAY_MED  = "#9CA3AF"   # íšŒìƒ‰(ë¡œìš°/ì¤‘ë¦½)
COL_BLACK     = "#111111"   # í¬ë ˆìŠ¤íŠ¸ í”Œë¡¯ìš©

# ì„¸ê·¸/í‹°ì–´ â†’ ìƒ‰ ë§¤í•‘ (ëª¨ë“  í‚¤ëŠ” ì†Œë¬¸ì ê¸°ì¤€ìœ¼ë¡œ ì €ì¥)
_SEG_TIER_COLOR = {
    # High/Premium ê³„ì—´
    "highend": COL_BLUE_DEEP, "high": COL_BLUE_DEEP, "premium": COL_BLUE_DEEP,
    "í•˜ì´ì—”ë“œ": COL_BLUE_DEEP, "í”„ë¦¬ë¯¸ì—„": COL_BLUE_DEEP,
    # Mid ê³„ì—´
    "midend": COL_BLUE_SKY, "mid": COL_BLUE_SKY, "midrange": COL_BLUE_SKY,
    "ë¯¸ë“œ": COL_BLUE_SKY, "ì¤‘ê°„": COL_BLUE_SKY,
    # Low/Entry ê³„ì—´
    "lowend": COL_GRAY_MED, "low": COL_GRAY_MED, "entry": COL_GRAY_MED,
    "ë¡œìš°ì—”ë“œ": COL_GRAY_MED, "ì €ê°€": COL_GRAY_MED,
}

def _norm_key(x) -> str:
    return "" if x is None else str(x).strip().lower()

def _tier_color_for_segment(seg: str) -> str:
    """ì„¸ê·¸ ì´ë¦„ì„ ëŠìŠ¨í•˜ê²Œ ë°›ì•„ ì»¬ëŸ¬ë¡œ ë§¤í•‘(ëŒ€ì†Œë¬¸ì/ê³µë°±/í•œê¸€ í—ˆìš©)."""
    return _SEG_TIER_COLOR.get(_norm_key(seg), COL_GRAY_MED)

def _model_dominant_segment(df_scope: pd.DataFrame) -> dict:
    """
    ëª¨ë¸ë³„ 'í‘œë³¸ìˆ˜ ê°€ì¤‘' ìš°ì„¸ ì„¸ê·¸. segmentê°€ ALL/ì „ì²´ì¸ í–‰ì€ ì œì™¸.
    ë°˜í™˜: {model(str): segment(str)}
    """
    if df_scope is None or df_scope.empty or "model" not in df_scope.columns or "segment" not in df_scope.columns:
        return {}

    s = df_scope.copy()
    # ALL/ì „ì²´ drop
    seg_norm = s["segment"].astype(str).str.strip()
    m_valid = ~seg_norm.isin(["ALL", "ì „ì²´"]) & seg_norm.notna()
    s = s[m_valid]
    if s.empty:
        return {}

    w = pd.to_numeric(s.get("pref_sample_size", 1), errors="coerce").replace([np.inf, -np.inf], np.nan).fillna(1.0)
    s["__w__"] = w

    grp = s.groupby(["model", "segment"], as_index=False)["__w__"].sum()
    # ê° ëª¨ë¸ì—ì„œ ê°€ì¤‘ì¹˜ ìµœëŒ€ì¸ ì„¸ê·¸ 1ê°œ ì„ íƒ
    dom = grp.sort_values(["model", "__w__"], ascending=[True, False]).drop_duplicates("model")
    return {str(r["model"]): str(r["segment"]) for _, r in dom.iterrows()}


# ===================== ì•± =====================
app = Dash(__name__)
app.title = "Bayesian Journey Dashboard"
px.defaults.template = "plotly_white"

def _safe_num(x, default=np.nan):
    try: return float(x)
    except Exception: return default

def _safe_int0(x):
    try:
        v = float(x)
        return int(v) if np.isfinite(v) else 0
    except Exception:
        return 0

def _norm_cols(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or df.empty: return pd.DataFrame()
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]
    for c in df.columns:
        if df[c].dtype == "O":
            ser = pd.to_numeric(df[c], errors="coerce")
            if ser.notna().mean() >= 0.5: df[c] = ser
    return df

def _ci_to_sd(lo, hi):
    lo = np.asarray(lo, dtype=float); hi = np.asarray(hi, dtype=float)
    return (hi - lo)/(2*1.96)

def _grade_from_p(p):
    if not np.isfinite(p): return "N/A"
    if p >= 0.70: return "A"
    if p >= 0.55: return "B"
    if p >= 0.45: return "C"
    return "D"

def _auto_dtick(span):
    # 0~1 í¼ì„¼íŠ¸ ì¶• span ê¸°ì¤€
    if span <= 0.30: return 0.05   # 5%
    if span >= 0.80: return 0.20   # 20%
    return 0.10                    # 10%

def apply_dense_grid(fig: go.Figure, x_prob: bool = False, y_prob: bool = False) -> go.Figure:
    # 1) ê¸°ì¡´ ë†’ì´ ë³´ì¡´(ì—†ì„ ë•Œë§Œ 360 ì§€ì •)
    cur_h = getattr(fig.layout, "height", None)
    fig.update_layout(
        height=(cur_h if cur_h is not None else 360),
        showlegend=True,
        paper_bgcolor="#fff",
        plot_bgcolor="#fff",
        font=dict(color="#111"),
        margin=dict(l=10, r=10, t=30, b=10),
    )

    # 2) ê¸°ë³¸ ê²©ì
    fig.update_xaxes(showgrid=True, gridcolor="#e5e7eb", gridwidth=0.8, zeroline=False)
    fig.update_yaxes(showgrid=True, gridcolor="#e5e7eb", gridwidth=0.8, zeroline=False)

    # 3) plotly ë²„ì „ë³„ minor ì˜µì…˜ ì•ˆì „ ì²˜ë¦¬
    try:
        fig.update_xaxes(minor=dict(showgrid=False))
        fig.update_yaxes(minor=dict(showgrid=False))
    except Exception:
        pass

    # 4) í™•ë¥ ì¶•(0~1) í¬ë§·
    if x_prob:
        xr = (getattr(fig.layout.xaxis, "range", None) or [0, 1])
        span = (xr[1] - xr[0]) if isinstance(xr, (list, tuple)) and len(xr) == 2 else 1.0
        fig.update_xaxes(tick0=0, dtick=_auto_dtick(span), tickformat=".0%")
    if y_prob:
        yr = (getattr(fig.layout.yaxis, "range", None) or [0, 1])
        span = (yr[1] - yr[0]) if isinstance(yr, (list, tuple)) and len(yr) == 2 else 1.0
        fig.update_yaxes(tick0=0, dtick=_auto_dtick(span), tickformat=".0%")

    # 5) ì¸í„°ë™ì…˜ ìƒíƒœ ìœ ì§€
    fig.update_layout(uirevision="keep")

    # 6) ë ˆì´ì•„ì›ƒ shape ì”ì¬(x0shift ë“±) ì „ì—­ ìŠ¤í¬ëŸ½
    try:
        fig = _scrub_layout_shapes(fig)  # sanitize_shape_dictë¥¼ ë‚´ë¶€ì—ì„œ í™œìš©
    except Exception:
        pass

    return fig


    # â˜… ì—¬ê¸° ì¶”ê°€: ëª¨ë“  shape ì •ì œ
    try:
        sanitize_fig_shapes(fig)
    except Exception:
        pass

    return fig


# ---- Excel ì˜¤í”ˆ(ì—”ì§„ í´ë°± + ë””ë²„ê·¸ ìˆ˜ì§‘) ----
def _open_excel_with_fallback(path: str):
    errs = []
    for eng in ["openpyxl", None, "xlrd"]:
        try:
            xls = pd.ExcelFile(path, engine=eng) if eng else pd.ExcelFile(path)
            return xls, (eng or "auto")
        except Exception as e:
            errs.append(f"{(eng or 'auto')}: {type(e).__name__}::{e}")
    raise RuntimeError("Excel open failed | " + " | ".join(errs))

def _find_sheet(xls: pd.ExcelFile, candidates):
    names = xls.sheet_names
    norm = lambda s: re.sub(r"\s+", "", str(s)).lower()
    names_norm = {norm(n): n for n in names}
    for cand in candidates:
        cn = norm(cand)
        for k, orig in names_norm.items():
            if cn in k:
                return orig
    return None

def load_excel(path: str):
    if not os.path.exists(path):
        raise FileNotFoundError(f"ì—‘ì…€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {path}")
    xls, used_engine = _open_excel_with_fallback(path)
    sheets = list(xls.sheet_names)

    sh_master = _find_sheet(xls, ["VBAë§ˆìŠ¤í„°í…Œì´ë¸”", "ë§ˆìŠ¤í„°", "master", "mastertable", "ë§ˆìŠ¤í„°í…Œì´ë¸”"])
    sh_tm     = _find_sheet(xls, ["ë² ì´ì§€ì•ˆì „ì´í™•ë¥ ë§¤íŠ¸ë¦­ìŠ¤", "ì „ì´í™•ë¥ ", "transition", "matrix"])
    sh_sankey = _find_sheet(xls, ["ë² ì´ì§€ì•ˆìƒí‚¤ë‹¤ì´ì–´ê·¸ë¨", "ìƒí‚¤", "sankey", "flow"])

    dbg = {"engine": used_engine, "sheets": sheets,
           "matched": {"master": sh_master, "tm": sh_tm, "sankey": sh_sankey}}

    if not sh_master:
        raise ValueError(f"í•„ìˆ˜ ì‹œíŠ¸(ë§ˆìŠ¤í„°) ë¯¸ë°œê²¬ | sheets={sheets}")

    df_master = _norm_cols(pd.read_excel(xls, sh_master))
    df_tm     = _norm_cols(pd.read_excel(xls, sh_tm)) if sh_tm else pd.DataFrame()
    df_sankey = _norm_cols(pd.read_excel(xls, sh_sankey)) if sh_sankey else pd.DataFrame()

    df_master = _rebuild_hkey_using_level(df_master)
    if not df_tm.empty: df_tm = _rebuild_hkey_using_level(df_tm)
    if not df_sankey.empty: df_sankey = _rebuild_hkey_using_level(df_sankey)

    def col(name): return df_master.get(name, pd.Series(np.nan, index=df_master.index))
    overall = {
        "pref_mean":   float(np.nanmean(col("pref_success_rate"))),
        "rec_mean":    float(np.nanmean(col("rec_success_rate"))),
        "intent_mean": float(np.nanmean(col("intent_success_rate"))),
        "buy_mean":    float(np.nanmean(col("buy_success_rate"))),
        "pref_sd":     float(np.nanmean(_ci_to_sd(col("pref_ci_lower"),   col("pref_ci_upper")))),
        "rec_sd":      float(np.nanmean(_ci_to_sd(col("rec_ci_lower"),    col("rec_ci_upper")))),
        "intent_sd":   float(np.nanmean(_ci_to_sd(col("intent_ci_lower"), col("intent_ci_upper")))),
        "buy_sd":      float(np.nanmean(_ci_to_sd(col("buy_ci_lower"),    col("buy_ci_upper")))),
    }

    seg_opts = ["ALL"] + sorted([str(v) for v in df_master["segment"].dropna().unique() if str(v)!="ALL"])
    loy_opts = ["ALL"] + sorted([str(v) for v in df_master["loyalty"].dropna().unique() if str(v)!="ALL"])
    mod_opts_all = ["ALL"] + sorted([str(v) for v in df_master["model"].dropna().unique() if str(v)!="ALL"])

    return df_master, df_tm, df_sankey, overall, seg_opts, mod_opts_all, loy_opts, dbg

# ===================== ì„ íƒ/ì§‘ê³„ ë¡œì§ =====================
def pick_row_for(df_master: pd.DataFrame, seg, mod, loy):
    seg = _as_all(seg); mod = _as_all(mod); loy = _as_all(loy)
    df  = _ensure_key_cols(df_master)

    sort_col = sample_col_in_df(df)
    if sort_col is None:
        sort_col = "__tmp_n__"; df[sort_col] = 1

    def add_pref_score(sub: pd.DataFrame) -> pd.DataFrame:
        # ì‚¬ìš©ìê°€ ALLë¡œ ë‘” ì°¨ì›ì€ ALLì„ ì„ í˜¸(=ëœ êµ¬ì²´ì ì¸ í–‰ì„ ìƒë‹¨ì—)
        score = 0
        if seg == "ALL": score += (sub["segment"]=="ALL").astype(int)
        if mod == "ALL": score += (sub["model"]=="ALL").astype(int)
        if loy == "ALL": score += (sub["loyalty"]=="ALL").astype(int)
        sub = sub.copy(); sub["__score__"] = score
        return sub

    chosen = (seg!="ALL") + (mod!="ALL") + (loy!="ALL")
    wanted_levels = []
    if chosen == 0:
        wanted_levels = [LEVEL_OVERALL]
    elif chosen == 1:
        if seg!="ALL": wanted_levels = [LEVEL_SEGMENT, LEVEL_OVERALL]
        if mod!="ALL": wanted_levels = [LEVEL_MODEL, LEVEL_OVERALL]
        if loy!="ALL": wanted_levels = [LEVEL_LOYALTY, LEVEL_OVERALL]
    elif chosen == 2:
        if seg!="ALL" and mod!="ALL":
            wanted_levels = [LEVEL_SEG_X_MODEL, LEVEL_SEGMENT, LEVEL_MODEL, LEVEL_OVERALL]
        elif seg!="ALL" and loy!="ALL":
            wanted_levels = [LEVEL_SEG_X_LOY, LEVEL_SEGMENT, LEVEL_LOYALTY, LEVEL_OVERALL]
        elif mod!="ALL" and loy!="ALL":
            wanted_levels = [LEVEL_MODEL_X_LOY, LEVEL_MODEL, LEVEL_LOYALTY, LEVEL_OVERALL]
    else:
        wanted_levels = [
            LEVEL_MOD_X_SEG_X_LOY, LEVEL_SEG_X_LOY, LEVEL_SEG_X_MODEL, LEVEL_MODEL_X_LOY,
            LEVEL_MODEL, LEVEL_SEGMENT, LEVEL_LOYALTY, LEVEL_OVERALL
        ]

    # 1) ë ˆë²¨ ìš°ì„  ë§¤ì¹­
    for lvl in wanted_levels:
        sub = df[df["level"] == lvl]
        if seg!="ALL": sub = sub[sub["segment"] == seg]
        if mod!="ALL": sub = sub[sub["model"]   == mod]
        if loy!="ALL": sub = sub[sub["loyalty"] == loy]
        if not sub.empty:
            sub = add_pref_score(sub).sort_values(["__score__", sort_col], ascending=[False, False])
            row = sub.iloc[0]
            return row.drop(labels=[c for c in ["__score__","__tmp_n__"] if c in row.index])

    # 2) ì •í™• ì¡°í•© ì‹¤íŒ¨ ì‹œ, ë¶€ë¶„ì¡°í•© ë§¤ì¹­
    sub = df.copy()
    if seg!="ALL": sub = sub[sub["segment"] == seg]
    if mod!="ALL": sub = sub[sub["model"]   == mod]
    if loy!="ALL": sub = sub[sub["loyalty"] == loy]
    if not sub.empty:
        sub = add_pref_score(sub).sort_values(["__score__", sort_col], ascending=[False, False])
        row = sub.iloc[0]
        return row.drop(labels=[c for c in ["__score__","__tmp_n__"] if c in row.index])

    # 3) ë‹¨ì¼ ì»¬ëŸ¼ë§Œ ë§ëŠ” í–‰ì´ë¼ë„
    for col, val in [("segment", seg), ("model", mod), ("loyalty", loy)]:
        if val != "ALL":
            sub = df[df[col]==val]
            if not sub.empty:
                sub = add_pref_score(sub).sort_values(["__score__", sort_col], ascending=[False, False])
                row = sub.iloc[0]
                return row.drop(labels=[c for c in ["__score__","__tmp_n__"] if c in row.index])

    # 4) ì™„ì „ ì‹¤íŒ¨ ì‹œ í‘œë³¸ìˆ˜ ìµœëŒ€
    row = df.sort_values(sort_col, ascending=False).iloc[0]
    return row.drop(labels=[c for c in ["__score__","__tmp_n__"] if c in row.index])

# ===================== ì°¨íŠ¸/í‘œ ìœ í‹¸ =====================
def _pick_sample_for_stage(r, stage_prefix: str) -> int:
    for c in [f"{stage_prefix}_sample_size", "sample_size", "n", "N", "base", "ë² ì´ìŠ¤ìˆ˜", "í‘œë³¸ìˆ˜"]:
        if c in r and pd.notna(r.get(c)):
            return _safe_int0(r.get(c))
    return _safe_int0(r.get("pref_sample_size"))

def metrics_table_row(r):
    def sd_from_ci(lo, hi):
        if pd.isna(lo) or pd.isna(hi): return np.nan
        return (hi - lo)/(2*1.96)
    rows = []
    mapping = [
        ("ì„ í˜¸",   "pref_success_rate",   "pref_ci_lower",   "pref_ci_upper",   "pref_snr",   "pref_lift_vs_galaxy"),
        ("ì¶”ì²œ", "rec_success_rate",    "rec_ci_lower",    "rec_ci_upper",    "rec_snr",    "rec_lift_vs_galaxy"),
        ("êµ¬ë§¤ì˜í–¥", "intent_success_rate", "intent_ci_lower", "intent_ci_upper", "intent_snr", "intent_lift_vs_galaxy"),
        ("êµ¬ë§¤",     "buy_success_rate",    "buy_ci_lower",    "buy_ci_upper",    "buy_snr",    "buy_lift_vs_galaxy"),
    ]
    for label, m, lo, hi, snr, lift in mapping:
        mval   = _safe_num(r.get(m))
        loval  = _safe_num(r.get(lo))
        hival  = _safe_num(r.get(hi))
        snrval = _safe_num(r.get(snr))
        liftval= _safe_num(r.get(lift))
        stage_prefix = m.split("_")[0]
        rows.append(dict(
            ë‹¨ê³„=label,
            ë² ì´ìŠ¤ìˆ˜=_pick_sample_for_stage(r, stage_prefix),
            ì„±ê³µí™•ë¥ =mval, í•˜í•œ=loval, ìƒí•œ=hival,
            ì‹¤íŒ¨í™•ë¥ =(None if pd.isna(mval) else 1-mval),
            íŒì •=("ì„±ê³µ" if (np.isfinite(mval) and mval>=0.5) else ("ì‹¤íŒ¨" if np.isfinite(mval) else "N/A")),
            í‰ê°€ë“±ê¸‰=("N/A" if not np.isfinite(mval) else ("A" if mval>=0.70 else "B" if mval>=0.55 else "C" if mval>=0.45 else "D")),
            SNR=snrval, Lift=liftval, rawí‰ê· =mval,
            rawí‘œì¤€í¸ì°¨=sd_from_ci(loval, hival)
        ))
    return pd.DataFrame(rows)

def drops_from_anywhere(row, df_tm, seg, mod, loy):
    seg = _as_all(seg); mod = _as_all(mod); loy = _as_all(loy)
    d1 = _safe_num(row.get("bayesian_dropout_pref_to_rec"))
    d2 = _safe_num(row.get("bayesian_dropout_rec_to_intent"))
    d3 = _safe_num(row.get("bayesian_dropout_intent_to_buy"))
    full = _safe_num(row.get("bayesian_full_conversion"))
    if df_tm is None or df_tm.empty:
        return d1, d2, d3, full
    need = [np.isfinite(d1), np.isfinite(d2), np.isfinite(d3), np.isfinite(full)]
    if all(need): return d1, d2, d3, full
    m = pd.Series(True, index=df_tm.index)
    if "segment" in df_tm and seg!="ALL": m &= (df_tm["segment"].astype(str)==seg)
    if "model"   in df_tm and mod!="ALL": m &= (df_tm["model"].astype(str)==mod)
    if "loyalty" in df_tm and loy!="ALL": m &= (df_tm["loyalty"].astype(str)==loy)
    sub = df_tm[m].copy()
    if sub.empty: sub = df_tm.copy()
    w = pd.to_numeric(sub.get("pref_sample_size", pd.Series(1, index=sub.index)), errors="coerce").fillna(1)
    def wmean(col):
        v = pd.to_numeric(sub.get(col, pd.Series(np.nan, index=sub.index)), errors="coerce")
        if v.notna().any(): return float(np.nansum(v*w)/np.nansum(w))
        return np.nan
    d1 = d1 if np.isfinite(d1) else wmean("bayesian_dropout_pref_to_rec")
    d2 = d2 if np.isfinite(d2) else wmean("bayesian_dropout_rec_to_intent")
    d3 = d3 if np.isfinite(d3) else wmean("bayesian_dropout_intent_to_buy")
    full = full if np.isfinite(full) else wmean("bayesian_full_conversion")
    return d1, d2, d3, full

def biggest_drop_text_by_sources(row, df_tm, seg, mod, loy):
    d1, d2, d3, _ = drops_from_anywhere(row, df_tm, seg, mod, loy)
    pairs = [("ì„ í˜¸â†’ì¶”ì²œ", d1), ("ì¶”ì²œâ†’êµ¬ë§¤ì˜í–¥", d2), ("êµ¬ë§¤ì˜í–¥â†’êµ¬ë§¤", d3)]
    pairs = [(n, v) for n, v in pairs if np.isfinite(v)]
    if not pairs: return "ë°ì´í„° ì—†ìŒ"
    name, val = max(pairs, key=lambda x: x[1])
    base_n = _safe_int0(row.get("pref_sample_size"))
    return f"{name}ì—ì„œ {val*100:.1f}%p ì†ì‹¤ (ìƒ˜í”Œ {base_n:,})"

def compose_composite_row(df_scope: pd.DataFrame) -> pd.Series:
    if df_scope is None or df_scope.empty:
        return pd.Series(dtype=float)
    s = df_scope.copy()
    w = pd.to_numeric(s.get("pref_sample_size", pd.Series(1, index=s.index)), errors="coerce").fillna(1.0)
    w_sum = float(np.nansum(w)) if np.isfinite(np.nansum(w)) and np.nansum(w) > 0 else 1.0
    w_norm = w / w_sum
    def wmean(col):
        v = pd.to_numeric(s.get(col, pd.Series(np.nan, index=s.index)), errors="coerce")
        if v.notna().any(): return float(np.nansum(v * w_norm))
        return np.nan
    def combine_ci(lo_col, hi_col, mean_col):
        m = pd.to_numeric(s.get(mean_col, pd.Series(np.nan, index=s.index)), errors="coerce")
        lo = pd.to_numeric(s.get(lo_col, pd.Series(np.nan, index=s.index)), errors="coerce")
        hi = pd.to_numeric(s.get(hi_col, pd.Series(np.nan, index=s.index)), errors="coerce")
        if not (m.notna().any() and lo.notna().any() and hi.notna().any()):
            return np.nan, np.nan
        m_bar = float(np.nansum(m * w_norm))
        sd = (hi - lo) / (2 * 1.96)
        sd = pd.to_numeric(sd, errors="coerce")
        var = np.nansum(w_norm * (sd**2 + (m - m_bar)**2))
        sd_c = float(np.sqrt(var)) if np.isfinite(var) else np.nan
        if not np.isfinite(sd_c): return np.nan, np.nan
        return (m_bar - 1.96 * sd_c), (m_bar + 1.96 * sd_c)
    pref_m   = wmean("pref_success_rate")
    rec_m    = wmean("rec_success_rate")
    intent_m = wmean("intent_success_rate")
    buy_m    = wmean("buy_success_rate")
    pref_lo, pref_hi     = combine_ci("pref_ci_lower",   "pref_ci_upper",   "pref_success_rate")
    rec_lo, rec_hi       = combine_ci("rec_ci_lower",    "rec_ci_upper",    "rec_success_rate")
    intent_lo, intent_hi = combine_ci("intent_ci_lower", "intent_ci_upper", "intent_success_rate")
    buy_lo, buy_hi       = combine_ci("buy_ci_lower",    "buy_ci_upper",    "buy_success_rate")
    d1 = wmean("bayesian_dropout_pref_to_rec")
    d2 = wmean("bayesian_dropout_rec_to_intent")
    d3 = wmean("bayesian_dropout_intent_to_buy")
    full = wmean("bayesian_full_conversion")
    pref_snr = wmean("pref_snr");  rec_snr = wmean("rec_snr")
    intent_snr = wmean("intent_snr"); buy_snr = wmean("buy_snr")
    pref_lift = wmean("pref_lift_vs_galaxy"); rec_lift = wmean("rec_lift_vs_galaxy")
    intent_lift = wmean("intent_lift_vs_galaxy"); buy_lift = wmean("buy_lift_vs_galaxy")
    out = {
        "pref_sample_size": float(np.nansum(w)),
        "pref_success_rate": pref_m, "pref_ci_lower": pref_lo, "pref_ci_upper": pref_hi,
        "rec_success_rate": rec_m, "rec_ci_lower": rec_lo, "rec_ci_upper": rec_hi,
        "intent_success_rate": intent_m, "intent_ci_lower": intent_lo, "intent_ci_upper": intent_hi,
        "buy_success_rate": buy_m, "buy_ci_lower": buy_lo, "buy_ci_upper": buy_hi,
        "bayesian_dropout_pref_to_rec": d1,
        "bayesian_dropout_rec_to_intent": d2,
        "bayesian_dropout_intent_to_buy": d3,
        "bayesian_full_conversion": full,
        "pref_snr": pref_snr, "rec_snr": rec_snr, "intent_snr": intent_snr, "buy_snr": buy_snr,
        "pref_lift_vs_galaxy": pref_lift, "rec_lift_vs_galaxy": rec_lift,
        "intent_lift_vs_galaxy": intent_lift, "buy_lift_vs_galaxy": buy_lift,
    }
    return pd.Series(out)

# ===================== ì°¨íŠ¸ =====================
def _empty_fig(msg="Load data first", height=360, hide_axes=False):
    fig = go.Figure()
    fig.add_annotation(text=msg, x=0.5, y=0.5, xref="paper", yref="paper", showarrow=False)
    fig.update_layout(
        height=height,
        margin=dict(l=10, r=10, t=30, b=10),
        paper_bgcolor="#ffffff",
        plot_bgcolor="#ffffff",
        uirevision="keep",
    )
    fig = apply_dense_grid(fig)  # ê¸°ì¡´ ìŠ¤íƒ€ì¼ ìœ ì§€

    if hide_axes:  # Sankey ë“± ì¹´í…Œì‹œì•ˆ ì¶•ì´ ë¶ˆí•„ìš”í•œ ê²½ìš°
        fig.update_xaxes(visible=False, showgrid=False, zeroline=False)
        fig.update_yaxes(visible=False, showgrid=False, zeroline=False)

    return fig

def hex_to_rgba(hex_color: str, a: float | None = None) -> str:
    s = hex_color.strip().lstrip("#")
    if len(s) in (3, 4):
        s = "".join(ch * 2 for ch in s)
    if len(s) == 6:
        r = int(s[0:2], 16); g = int(s[2:4], 16); b = int(s[4:6], 16)
        alpha = 1.0 if a is None else float(a)
    elif len(s) == 8:
        r = int(s[0:2], 16); g = int(s[2:4], 16); b = int(s[4:6], 16)
        hex_alpha = int(s[6:8], 16) / 255.0
        alpha = hex_alpha if a is None else float(a)
    else:
        raise ValueError("hex must be #RGB, #RRGGBB, or #RRGGBBAA")
    alpha = max(0.0, min(1.0, alpha))
    return f"rgba({r},{g},{b},{alpha:.3g})"


def _normalize_stage_label(v: str) -> str | None:
    if v is None:
        return None
    s = str(v).strip().lower()
    s = re.sub(r'[\s\-\_]+', ' ', s)           # ê³µë°±/-,_ ì •ë¦¬
    joined = s.replace(' ', '')

    # ì „ì²´
    if any(k in (s, joined) for k in [
        "overall","total","all","ì „ì²´","ì „ì²´ì‚¬ìš©ì","ëª¨ë“ ì‚¬ìš©ì","allusers","all user","all-user"
    ]):
        return "ì „ì²´"

    # ë¯¸ì„ í˜¸(ë¹„ì„ í˜¸/íƒˆë½/ë“œë/No preference ë“±)
    if any(k in (s, joined) for k in [
        "ë¯¸ì„ í˜¸","ë¹„ì„ í˜¸","ì„ í˜¸ì•„ë‹˜","ì„ í˜¸ ì•„ë‹˜",
        "nopref","no preference","dislike","íƒˆë½","drop","dropped"
    ]):
        return "ë¯¸ì„ í˜¸"

    # êµ¬ë§¤ì˜í–¥(ì˜í–¥/ì˜ë„/ì˜ì‚¬/intent ê³„ì—´)
    if ("ì˜í–¥" in s) or ("ì˜ë„" in s) or ("ì˜ì‚¬" in s) \
       or ("intent" in s) or ("intention" in s) \
       or ("purchaseintent" in joined) or ("purchase-intent" in s):
        return "êµ¬ë§¤ì˜í–¥"

    # êµ¬ë§¤(ì‹¤ì œêµ¬ë§¤/êµ¬ë§¤ì™„ë£Œ/êµ¬ë§¤í™•ì •/êµ¬ì…/ê²°ì œ/ë§¤ì¶œ/buy/purchase)
    if ("êµ¬ë§¤" in s) or ("êµ¬ì…" in s) or ("ê²°ì œ" in s) or ("ê²°ì¬" in s) or ("ë§¤ì¶œ" in s) \
       or (s == "buy") or ("purchase" in s):
        return "êµ¬ë§¤"

    # ì„ í˜¸
    if ("ì„ í˜¸" in s) or ("í˜¸ê°" in s) or ("preference" in s) or (s == "pref"):
        return "ì„ í˜¸"

    # ì¶”ì²œ
    if (s == "rec") or ("recommend" in s) or ("ì¶”ì²œ" in s):
        return "ì¶”ì²œ"

    return None

# ==== STAGES & ORDER (ê¸°ì¡´ ê²ƒì„ êµì²´) ====
STAGES = ["ì „ì²´", "ë¯¸ì„ í˜¸", "ì„ í˜¸", "ì¶”ì²œ", "êµ¬ë§¤ì˜í–¥", "êµ¬ë§¤"]
ORDER  = {v:i for i,v in enumerate(STAGES)}

# ìƒ‰ìƒ í•˜ë‚˜ ì¶”ê°€(ì€ì€í•œ íšŒìƒ‰ ê³„ì—´ ê¶Œì¥)
COL_STAGE_DROP = "#CBD5E1"  # ë¯¸ì„ í˜¸

def _group_forward_flows(df_sankey, seg, mod, loy):
    if df_sankey is None or df_sankey.empty:
        return pd.DataFrame(columns=["from_stage","to_stage","count","flow_phi"])
    seg = _as_all(seg); mod = _as_all(mod); loy = _as_all(loy)
    s = df_sankey.copy()
    m = pd.Series(True, index=s.index)
    if "segment" in s and seg!="ALL": m &= (s["segment"].astype(str)==seg)
    if "model"   in s and mod!="ALL": m &= (s["model"].astype(str)==mod)
    if "loyalty" in s and loy!="ALL": m &= (s["loyalty"].astype(str)==loy)
    s = s[m].copy()
    if s.empty: 
        return pd.DataFrame(columns=["from_stage","to_stage","count","flow_phi"])

    alias = {
        "all":"ì „ì²´","ALL":"ì „ì²´","ì „ì²´":"ì „ì²´",
        "pref":"ì„ í˜¸","preference":"ì„ í˜¸","ì„ í˜¸ë„":"ì„ í˜¸",
        "rec":"ì¶”ì²œ","recommend":"ì¶”ì²œ","ì¶”ì²œë„":"ì¶”ì²œ",
        "intent":"êµ¬ë§¤ì˜í–¥","intention":"êµ¬ë§¤ì˜í–¥","êµ¬ë§¤ì˜ë„":"êµ¬ë§¤ì˜í–¥",
        "purchase":"êµ¬ë§¤","buy":"êµ¬ë§¤","ì‹¤ì œêµ¬ë§¤":"êµ¬ë§¤"
    }
    s["from_stage"] = s.get("from_stage", s.get("from", s.get("source"))).astype(str).str.strip().replace(alias)
    s["to_stage"]   = s.get("to_stage",   s.get("to",   s.get("target"))).astype(str).str.strip().replace(alias)

    # ğŸ”‘ count ë³„ì¹­ í—ˆìš©
    cnt_cands = ["bayesian_flow_count","count","value","weight","n","freq"]
    cnt_col = next((c for c in cnt_cands if c in s.columns), None)
    if cnt_col is None:
        return pd.DataFrame(columns=["from_stage","to_stage","count","flow_phi"])

    s[cnt_col] = pd.to_numeric(s[cnt_col], errors="coerce")
    s = s[np.isfinite(s[cnt_col]) & (s[cnt_col]>0)]
    s = s[s["from_stage"].isin(STAGES) & s["to_stage"].isin(STAGES)]
    s = s[s.apply(lambda r: ORDER[r["from_stage"]] < ORDER[r["to_stage"]], axis=1)]
    if s.empty:
        return pd.DataFrame(columns=["from_stage","to_stage","count","flow_phi"])

    g = (s.groupby(["from_stage","to_stage"], as_index=False)[cnt_col]
           .sum().rename(columns={cnt_col:"count"}))

    # [ìœ ì… ì—†ëŠ” ë‹¨ê³„ ë³´ê°•] ì „ì²´â†’ë‹¨ê³„ ë§í¬ ìë™ ì¶”ê°€
    pairs = set(zip(g["from_stage"], g["to_stage"]))
    def _has_incoming(stage):
        k = ORDER[stage]
        return any((prev, stage) in pairs for prev in STAGES[:k])

    add_rows = []
    for st in STAGES[1:]:
        if not _has_incoming(st):
            out_sum = float(g.loc[g["from_stage"] == st, "count"].sum())
            if out_sum > 0:
                add_rows.append({"from_stage": "ì „ì²´", "to_stage": st, "count": out_sum})
    if add_rows:
        g = pd.concat([g, pd.DataFrame(add_rows)], ignore_index=True)

    # Ï† ìŠ¤ì¼€ì¼ ì ìš©
    k = _flow_scale(seg, mod, loy)
    g["flow_phi"] = g["count"].astype(float) * k
    return g

# ===== Sankey ë‚´ë¶€ìš© í…Œì´ë¸” ë¹Œë”(ê°„ì ‘ í¬í•¨, êµ¬ë§¤ë¡œ ì ‘ê¸° ì˜µì…˜) =====

# ë…¸ë“œ(ë² ì´ì§€) & ë§í¬(íšŒìƒ‰) íŒ”ë ˆíŠ¸
COL_STAGE_OVERALL = "#B68E5C"   # ì „ì²´
COL_STAGE_PREF    = "#C6955E"   # ì„ í˜¸
COL_STAGE_REC     = "#D5A86D"   # ì¶”ì²œ
COL_STAGE_INTENT  = "#BE8F4E"   # ì˜í–¥
COL_STAGE_BUY     = "#A97F45"   # êµ¬ë§¤
COL_LINK_DIRECT   = "#4B5563"   # ì§ì ‘(ì§™ì€ íšŒìƒ‰)
COL_LINK_INDIRECT = "#D1D5DB"   # ê°„ì ‘(ì—°í•œ íšŒìƒ‰)

def _sankey_build_table(df_sankey, seg="ALL", mod="ALL", loy="ALL",
                        collapse_to_buy=True, collapse_from=("ì„ í˜¸","ì¶”ì²œ","êµ¬ë§¤ì˜í–¥")) -> pd.DataFrame:
    if df_sankey is None or df_sankey.empty:
        return pd.DataFrame(columns=["from_stage","to_stage","count","dist","kind","to_buy","flow_phi"])

    s = df_sankey.copy()

    # --- [NEW] í˜¸í™˜ ê°€ë“œ: ì—´ ë³„ì¹­ì„ í‘œì¤€ ì´ë¦„ìœ¼ë¡œ í†µì¼ ---
    # 1) from/to ë³„ì¹­ â†’ from_stage/to_stage
    from_col = next((c for c in ["from_stage","from","source","src"] if c in s.columns), None)
    to_col   = next((c for c in ["to_stage","to","target","dst"]     if c in s.columns), None)
    if from_col and from_col != "from_stage":
        s = s.rename(columns={from_col: "from_stage"})
    if to_col and to_col != "to_stage":
        s = s.rename(columns={to_col: "to_stage"})

    # í•„ìˆ˜ ì—´ ì—†ìœ¼ë©´ ë¹ˆ í…Œì´ë¸” ë°˜í™˜ (ì•ˆì „ ê°€ë“œ)
    if "from_stage" not in s.columns or "to_stage" not in s.columns:
        return pd.DataFrame(columns=["from_stage","to_stage","count","dist","kind","to_buy","flow_phi"])

    # 2) ìˆ˜ì¹˜ ì—´ ë³„ì¹­ â†’ bayesian_flow_count
    alt_cnt = next((c for c in ["bayesian_flow_count","count","value","flow","weight","n","freq"]
                    if c in s.columns), None)
    if alt_cnt and alt_cnt != "bayesian_flow_count":
        s = s.rename(columns={alt_cnt: "bayesian_flow_count"})


    # í•„í„°
    for col, val in (("segment", seg), ("model", mod), ("loyalty", loy)):
        if col in s.columns and str(val) != "ALL":
            s = s[s[col].astype(str) == str(val)]
    if s.empty:
        return pd.DataFrame(columns=["from_stage","to_stage","count","dist","kind","to_buy","flow_phi"])

    # ë¼ë²¨ ì •ê·œí™” â†’ ìˆœë°©í–¥ë§Œ
    s["from_stage"] = s.get("from_stage", s.get("from", s.get("source"))).map(_normalize_stage_label)
    s["to_stage"]   = s.get("to_stage",   s.get("to",   s.get("target"))).map(_normalize_stage_label)
    s = s.dropna(subset=["from_stage","to_stage"])
    s = s[s["from_stage"].isin(STAGES) & s["to_stage"].isin(STAGES)]
    s = s[s.apply(lambda r: ORDER[r["from_stage"]] < ORDER[r["to_stage"]], axis=1)]
    
# ğŸ”‘ count ì»¬ëŸ¼ ë³„ì¹­ í—ˆìš© (ì›ì²œ ì‹œíŠ¸/ìºì‹œ ì‹œíŠ¸ ëª¨ë‘ ì»¤ë²„)
    cnt_cands = ["bayesian_flow_count", "count", "value", "weight", "n", "freq"]
    cnt_col = next((c for c in cnt_cands if c in s.columns), None)
    if cnt_col is None:
        return pd.DataFrame(columns=["from_stage","to_stage","count","dist","kind","to_buy","flow_phi"])

    s[cnt_col] = pd.to_numeric(s[cnt_col], errors="coerce")
    s = s[np.isfinite(s[cnt_col]) & (s[cnt_col] > 0)]
    if s.empty:
        return pd.DataFrame(columns=["from_stage","to_stage","count","dist","kind","to_buy","flow_phi"])

    # ê¸°ë³¸ ì§‘ê³„
    g = (s.groupby(["from_stage","to_stage"], as_index=False)[cnt_col]
           .sum().rename(columns={cnt_col:"count"}))

    # ìœ ì… ì—†ëŠ” ë‹¨ê³„ ë³´ê°•(ì „ì²´â†’ë‹¨ê³„)
    pairs = set(zip(g["from_stage"], g["to_stage"]))
    def _has_incoming(stage):
        k = ORDER[stage]
        return any((prev, stage) in pairs for prev in STAGES[:k])
    add_rows = []
    for st in STAGES[1:]:
        if not _has_incoming(st):
            out_sum = float(g.loc[g["from_stage"]==st, "count"].sum())
            if out_sum > 0:
                add_rows.append({"from_stage":"ì „ì²´","to_stage":st,"count":out_sum})
    if add_rows:
        g = pd.concat([g, pd.DataFrame(add_rows)], ignore_index=True)

    # (ì˜µì…˜) êµ¬ë§¤ë¡œ ì ‘ì€ ê°„ì ‘ ë§í¬ ì¶”ê°€: ì„ í˜¸/ì¶”ì²œ/êµ¬ë§¤ì˜í–¥ â†’ êµ¬ë§¤
    if collapse_to_buy:
        buy_in = float(pd.to_numeric(g.loc[g["to_stage"]=="êµ¬ë§¤","count"], errors="coerce").fillna(0).sum())
        if buy_in > 0:
            exist = set(zip(g["from_stage"], g["to_stage"]))
            extra = []
            for st in collapse_from:
                if st in ORDER and (st, "êµ¬ë§¤") not in exist and ORDER[st] < ORDER["êµ¬ë§¤"]:
                    extra.append({"from_stage": st, "to_stage": "êµ¬ë§¤", "count": buy_in})
            if extra:
                g = pd.concat([g, pd.DataFrame(extra)], ignore_index=True)

    # ë©”íƒ€ ì¹¼ëŸ¼
    kphi = _flow_scale(seg, mod, loy)  # ë¹„ê³µê°œ ìŠ¤ì¼€ì¼
    g["flow_phi"] = g["count"].astype(float) * kphi
    g["dist"]     = g["to_stage"].map(ORDER) - g["from_stage"].map(ORDER)
    g["kind"]     = np.where(g["dist"]==1, "ì§ì ‘", "ê°„ì ‘")
    g["to_buy"]   = (g["to_stage"] == "êµ¬ë§¤")

    cols = ["from_stage","to_stage","count","dist","kind","to_buy","flow_phi"]
    return g[cols].sort_values(["dist","from_stage","to_stage"]).reset_index(drop=True)


# ====== Sankey ìƒ‰/ìŠ¤í…Œì´ì§€ ======
STAGES = ["ì „ì²´","ë¯¸ì„ í˜¸","ì„ í˜¸","ì¶”ì²œ","êµ¬ë§¤ì˜í–¥","êµ¬ë§¤"]
ORDER  = {v:i for i,v in enumerate(STAGES)}

COL_STAGE_OVERALL = "#B68E5C"
COL_STAGE_NONPREF = "#9CA3AF"  # â† ë¯¸ì„ í˜¸(íšŒìƒ‰)
COL_STAGE_PREF    = "#C6955E"
COL_STAGE_REC     = "#D5A86D"
COL_STAGE_INTENT  = "#BE8F4E"
COL_STAGE_BUY     = "#A97F45"

COL_LINK_DIRECT   = "#4B5563"   # ì§™ì€ íšŒìƒ‰ (ì§ì ‘)
COL_LINK_INDIRECT = "#D1D5DB"   # ì—°í•œ íšŒìƒ‰ (ê°„ì ‘)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# (ìœ í‹¸) ê°„ì ‘ "â†’êµ¬ë§¤" ì ‘ê¸° ë³´ê°•
def add_collapsed_to_buy(tbl: pd.DataFrame, add_from=("ì„ í˜¸","ì¶”ì²œ","êµ¬ë§¤ì˜í–¥")) -> pd.DataFrame:
    if tbl is None or tbl.empty:
        return tbl

    # â”€â”€ ê¸°ì¤€ ë‹¨ê³„/ìˆœì„œ(ë¯¸ì„ í˜¸ í¬í•¨ 6ë‹¨ê³„)
    stages = ["ì „ì²´","ë¯¸ì„ í˜¸","ì„ í˜¸","ì¶”ì²œ","êµ¬ë§¤ì˜í–¥","êµ¬ë§¤"]
    order  = {v:i for i,v in enumerate(stages)}
    t = tbl.copy()

    # â”€â”€ êµ¬ë§¤ ìœ ì… ì´ëŸ‰
    buy_in = float(pd.to_numeric(t.loc[t["to_stage"]=="êµ¬ë§¤","count"], errors="coerce").fillna(0).sum())

    # â”€â”€ Ï† ìŠ¤ì¼€ì¼(k) ì¶”ì •
    kphi = 1.0
    if "flow_phi" in t.columns and "count" in t.columns:
        r = pd.to_numeric(t["flow_phi"], errors="coerce") / pd.to_numeric(t["count"], errors="coerce")
        r = r.replace([np.inf,-np.inf], np.nan).dropna()
        if not r.empty:
            kphi = float(np.median(r))

    # â”€â”€ ê·¸ë£¹ ë©”íƒ€(snapshot): ë‹¨ì¼ê°’ì´ë©´ ê·¸ ê°’, ì•„ë‹ˆë©´ "ALL"
    meta_cols = [c for c in ["segment","model","loyalty","level"] if c in t.columns]
    meta = {c: (t[c].dropna().iloc[0] if t[c].nunique(dropna=True)==1 else "ALL") for c in meta_cols}

    extra = []
    for s in add_from:
        if s not in order or order[s] >= order["êµ¬ë§¤"]:
            continue
        # ì´ë¯¸ ì¡´ì¬í•˜ë©´ ì¤‘ë³µ ì¶”ê°€ ê¸ˆì§€
        if ((t["from_stage"]==s) & (t["to_stage"]=="êµ¬ë§¤")).any():
            continue
        row = {
            "from_stage": s,
            "to_stage":   "êµ¬ë§¤",
            "count":      buy_in,
            "dist":       order["êµ¬ë§¤"] - order[s],
            "kind":       ("ê°„ì ‘" if (order["êµ¬ë§¤"] - order[s]) > 1 else "ì§ì ‘"),
            "to_buy":     True,
            "flow_phi":   buy_in * kphi
        }
        # â˜… ë©”íƒ€ ë™ë´‰
        for c, v in meta.items():
            row[c] = v
        extra.append(row)

    if extra:
        t = pd.concat([t, pd.DataFrame(extra)], ignore_index=True)

    return t.sort_values(["dist","from_stage","to_stage"]).reset_index(drop=True)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# â¬‡â¬‡ í•µì‹¬ ìˆ˜ì •: ë¼ë²¨ì„ ë¨¼ì € ëŠìŠ¨í•œ ë³„ì¹­ìœ¼ë¡œ ì¹˜í™˜ í›„, ì •ê·œí™” í•¨ìˆ˜ì— íƒœì›€
def _normalize_stage_soft(series: pd.Series) -> pd.Series:
    if series.empty:
        return series
    s = series.astype(str).str.strip()

    # 1) ê°•ì œ ë³„ì¹­(ì •í™•ì¹˜í™˜) â€” ì˜í–¥/ì˜ë„/ì˜ì‚¬/intent, êµ¬ë§¤ì™„ë£Œ/ì‹¤ì œêµ¬ë§¤, ì „ì²´ì‚¬ìš©ì ë“±
    alias_exact = {
        # ì „ì²´
        "ì „ì²´ì‚¬ìš©ì": "ì „ì²´", "ëª¨ë“  ì‚¬ìš©ì": "ì „ì²´", "all": "ì „ì²´", "ALL": "ì „ì²´",
        # ì„ í˜¸
        "ì„ í˜¸ë„": "ì„ í˜¸", "ì„ í˜¸ë„ë†’ìŒ": "ì„ í˜¸", "í˜¸ê°ë„": "ì„ í˜¸", "í˜¸ê°ë„ë†’ìŒ": "ì„ í˜¸",
        # ì¶”ì²œ
        "ì¶”ì²œë„": "ì¶”ì²œ", "ì¶”ì²œë„ë†’ìŒ": "ì¶”ì²œ",
        # ì˜í–¥/ì˜ë„/ì˜ì‚¬/intent (ë‹¤ì–‘í˜•)
        "êµ¬ë§¤ì˜í–¥": "êµ¬ë§¤ì˜í–¥", "êµ¬ë§¤ ì˜í–¥": "êµ¬ë§¤ì˜í–¥", "êµ¬ë§¤ì˜í–¥ë†’ìŒ": "êµ¬ë§¤ì˜í–¥", "êµ¬ë§¤ì˜í–¥ ë†’ìŒ": "êµ¬ë§¤ì˜í–¥",
        "êµ¬ë§¤ì˜ë„": "êµ¬ë§¤ì˜í–¥", "êµ¬ë§¤ ì˜ë„": "êµ¬ë§¤ì˜í–¥", "êµ¬ë§¤ì˜ë„ë†’ìŒ": "êµ¬ë§¤ì˜í–¥", "êµ¬ë§¤ì˜ë„ ë†’ìŒ": "êµ¬ë§¤ì˜í–¥",
        "êµ¬ë§¤ì˜ì‚¬": "êµ¬ë§¤ì˜í–¥", "ì˜ì‚¬ ìˆìŒ": "êµ¬ë§¤ì˜í–¥",
        "intent": "êµ¬ë§¤ì˜í–¥", "Intent": "êµ¬ë§¤ì˜í–¥", "Intention": "êµ¬ë§¤ì˜í–¥",
        "Purchase Intent": "êµ¬ë§¤ì˜í–¥", "PURCHASE_INTENT": "êµ¬ë§¤ì˜í–¥",
        # êµ¬ë§¤
        "ì‹¤ì œêµ¬ë§¤": "êµ¬ë§¤", "êµ¬ë§¤ í™•ì •": "êµ¬ë§¤", "êµ¬ë§¤í™•ì •": "êµ¬ë§¤", "êµ¬ë§¤ ì™„ë£Œ": "êµ¬ë§¤", "êµ¬ë§¤ì™„ë£Œ": "êµ¬ë§¤",
        "ê²°ì œ": "êµ¬ë§¤", "ê²°ì¬": "êµ¬ë§¤", "ë§¤ì¶œ": "êµ¬ë§¤",
        #ë¯¸ì„ í˜¸
        "ë¯¸ì„ í˜¸": "ë¯¸ì„ í˜¸", "ë¹„ì„ í˜¸": "ë¯¸ì„ í˜¸", "ì„ í˜¸ ì•„ë‹˜": "ë¯¸ì„ í˜¸", "íƒˆë½": "ë¯¸ì„ í˜¸",
    }
    s = s.replace(alias_exact)

    # 2) í† í°/ë¶€ë¶„ì¼ì¹˜ ê¸°ë°˜ ì •ê·œí™”(ì „ì—­ í•¨ìˆ˜ê°€ ìˆìœ¼ë©´ ì¬ì‚¬ìš©)
    def _norm_one(x: str) -> str | None:
        try:
            return _normalize_stage_label(x)  # ì „ì—­ ì •ì˜ ì¡´ì¬ ì‹œ í™œìš©
        except Exception:
            pass
        # í´ë°±: ë¶€ë¶„ì¼ì¹˜
        xl = x.lower().replace(" ", "")
        if any(k in xl for k in ["all","ì „ì²´"]): return "ì „ì²´"
        if any(k in xl for k in ["ì„ í˜¸","í˜¸ê°"]): return "ì„ í˜¸"
        if "ì¶”ì²œ" in xl or "rec" in xl: return "ì¶”ì²œ"
        if any(k in xl for k in ["ì˜í–¥","ì˜ë„","ì˜ì‚¬","intent"]): return "êµ¬ë§¤ì˜í–¥"
        if any(k in xl for k in ["êµ¬ë§¤","êµ¬ì…","ê²°ì œ","ê²°ì¬","ì™„ë£Œ","í™•ì •","ë§¤ì¶œ","purch","buy"]): return "êµ¬ë§¤"
        if any(k in xl for k in ["ë¯¸ì„ í˜¸","ë¹„ì„ í˜¸","ì„ í˜¸ì•„ë‹˜","nopref","npreference","íƒˆë½","drop"]): return "ë¯¸ì„ í˜¸"
        return None

    return s.map(_norm_one)


# íŒŒì¼ ìƒë‹¨ ì–´ë”˜ê°€(ìƒìˆ˜ë“¤ ê·¼ì²˜)ì— ì¶”ê°€
LVL_PRIORITY = [
    "ëª¨ë¸Ã—ì„¸ê·¸Ã—ì¶©ì„±ë„","ì„¸ê·¸Ã—ëª¨ë¸","ëª¨ë¸Ã—ì¶©ì„±ë„","ì„¸ê·¸Ã—ì¶©ì„±ë„",
    "ëª¨ë¸","ì„¸ê·¸ë¨¼íŠ¸","ì¶©ì„±ë„","ì „ì²´"
]

def _sanitize_sankey_table(
    tbl: pd.DataFrame,
    seg="ALL", mod="ALL", loy="ALL",
    enforce_single_level: bool = True,
    drop_overall_if_mixed: bool = True
) -> pd.DataFrame:
    cols = ["from_stage","to_stage","count","dist","kind","to_buy","flow_phi"]
    if tbl is None or tbl.empty:
        return pd.DataFrame(columns=cols)

    t = tbl.copy()

    # (1) ì„ íƒê°’ í•„í„° (ìˆì„ ë•Œë§Œ)
    for col, val in (("segment", seg), ("model", mod), ("loyalty", loy)):
        if col in t.columns and str(val) != "ALL":
            t = t[t[col].astype(str).str.strip() == str(val)]
    if t.empty:
        return pd.DataFrame(columns=cols)

    # (2) ë ˆë²¨ ë‹¨ì¼í™” (í˜¼ì… ë°©ì§€) + ê³¼ì‰ ë“œë ì™„í™”
    original = t
    if enforce_single_level and "level" in t.columns:
        picked = None
        for lv in LVL_PRIORITY:
            cand = t[t["level"].astype(str) == lv]
            if not cand.empty:
                picked = cand; break
        if picked is not None:
            t = picked
    # í˜¼í•©ì´ë©´ 'ì „ì²´'ë§Œ ì œê±° (ë‹¨, ì „ë¶€ ë¹„ë©´ ë˜ëŒë¦¼)
    if ("level" in t.columns) and (t["level"].astype(str).nunique() > 1) and drop_overall_if_mixed:
        t2 = t[t["level"].astype(str) != "ì „ì²´"]
        if not t2.empty:
            t = t2

    if t.empty:
        # ê³¼ì‰ í•„í„°/ë“œëìœ¼ë¡œ ë¹„ì—ˆìœ¼ë©´ ì›ë³¸ìœ¼ë¡œ ë˜ëŒë ¤ ê³„ì†
        t = original.copy()

    # (3) ì»¬ëŸ¼ ë³„ì¹­
    alias = {
        "from_stage": ["from_stage","from","source","src"],
        "to_stage":   ["to_stage","to","target","dst"],
        "count":      ["count","bayesian_flow_count","flow","value","weight","n","freq"],
    }
    def pick(name):
        keys = {str(c).strip().lower(): c for c in t.columns}
        for a in alias[name]:
            if a in keys: return keys[a]
        return None
    c_from = pick("from_stage"); c_to = pick("to_stage"); c_cnt = pick("count")
    if not all([c_from, c_to, c_cnt]):
        return pd.DataFrame(columns=cols)

    t = t.rename(columns={c_from:"from_stage", c_to:"to_stage", c_cnt:"count"})

    # (4) ë¼ë²¨ ì •ê·œí™” + ìˆœë°©í–¥ë§Œ
    t["from_stage"] = _normalize_stage_soft(t["from_stage"])
    t["to_stage"]   = _normalize_stage_soft(t["to_stage"])
    t = t.dropna(subset=["from_stage","to_stage"])
    t = t[t["from_stage"].isin(STAGES) & t["to_stage"].isin(STAGES)]
    t = t[t.apply(lambda r: ORDER[r["from_stage"]] < ORDER[r["to_stage"]], axis=1)]

    # (5) ìˆ˜ì¹˜ ë³€í™˜
    t["count"] = pd.to_numeric(t["count"], errors="coerce")
    t = t[np.isfinite(t["count"]) & (t["count"] > 0)]

    # (5-ë³´ê°•) ê³¼ë„ í•„í„°ë¡œ ë¹„ë©´ ì™„í™” ëª¨ë“œ: ë‹¨ê³„ ì¡°ê±´ë§Œ ì ìš©í•˜ê³  ìˆ˜ì¹˜ë§Œ ë³´ì •
    if t.empty:
        t = original.rename(columns={c_from:"from_stage", c_to:"to_stage", c_cnt:"count"}).copy()
        t["from_stage"] = _normalize_stage_soft(t["from_stage"])
        t["to_stage"]   = _normalize_stage_soft(t["to_stage"])
        t = t.dropna(subset=["from_stage","to_stage"])
        t = t[t["from_stage"].isin(STAGES) & t["to_stage"].isin(STAGES)]
        t["count"] = pd.to_numeric(t["count"], errors="coerce").fillna(0)
        t = t[t["count"] > 0]
        if t.empty:
            return pd.DataFrame(columns=cols)

    # (6) ë©”íƒ€ ë³´ê°•
    t["dist"] = (t["to_stage"].map(ORDER) - t["from_stage"].map(ORDER)).astype(int)
    if "kind" not in t.columns:
        t["kind"] = np.where(t["dist"]==1, "ì§ì ‘", "ê°„ì ‘")
    else:
        miss = ~t["kind"].astype(str).isin(["ì§ì ‘","ê°„ì ‘"])
        t.loc[miss,"kind"] = np.where(t.loc[miss,"dist"]==1, "ì§ì ‘","ê°„ì ‘")
    t["to_buy"] = (t["to_stage"]=="êµ¬ë§¤")

    # (7) Ï†
    kphi = _flow_scale(seg, mod, loy)
    if "flow_phi" not in t.columns:
        t["flow_phi"] = t["count"].astype(float) * kphi
    else:
        t["flow_phi"] = pd.to_numeric(t["flow_phi"], errors="coerce")
        miss = ~np.isfinite(t["flow_phi"])
        t.loc[miss, "flow_phi"] = t.loc[miss, "count"].astype(float) * kphi

    return t[cols].sort_values(["dist","from_stage","to_stage"]).reset_index(drop=True)


def _sankey_from_master_row(row: pd.Series, seg, mod, loy) -> pd.DataFrame:
    n = _safe_int0(row.get("pref_sample_size"))
    if n <= 0:
        return pd.DataFrame(columns=[
            "from_stage","to_stage","count","dist","kind","to_buy","flow_phi",
            "segment","model","loyalty"
        ])

    def P(x):
        v = _safe_num(x)
        if not np.isfinite(v): return np.nan
        return v/100.0 if v > 1.5 else v

    # (A) í™•ë¥  ì•ˆì „í™”: NaNì´ë©´ 0, 0~1ë¡œ í´ë¦½
    def P01(x):
        v = P(x)
        return np.nan if not np.isfinite(v) else float(min(1.0, max(0.0, v)))

    p_pref   = P(row.get("pref_success_rate"))
    p_rec    = P(row.get("rec_success_rate"))
    p_intent = P(row.get("intent_success_rate"))
    p_buy    = P(row.get("buy_success_rate"))
    d1       = P(row.get("bayesian_dropout_pref_to_rec"))
    d2       = P(row.get("bayesian_dropout_rec_to_intent"))
    d3       = P(row.get("bayesian_dropout_intent_to_buy"))

    pref   = n * (p_pref if np.isfinite(p_pref) else 0.0)
    rec    = pref * (1 - d1) if np.isfinite(pref)   and np.isfinite(d1) else n * (p_rec    if np.isfinite(p_rec)    else 0.0)
    intent = rec  * (1 - d2) if np.isfinite(rec)    and np.isfinite(d2) else n * (p_intent if np.isfinite(p_intent) else 0.0)
    buy    = intent*(1 - d3) if np.isfinite(intent) and np.isfinite(d3) else n * (p_buy    if np.isfinite(p_buy)    else 0.0)

    drop0 = max(0.0, float(n) - float(pref))

    rows = [
        {"from_stage":"ì „ì²´","to_stage":"ë¯¸ì„ í˜¸", "count": drop0}, 
        {"from_stage":"ì „ì²´","to_stage":"ì„ í˜¸", "count": pref},     
        {"from_stage":"ì„ í˜¸","to_stage":"ì¶”ì²œ",     "count":max(0.0, rec)},
        {"from_stage":"ì¶”ì²œ","to_stage":"êµ¬ë§¤ì˜í–¥", "count":max(0.0, intent)},
        {"from_stage":"êµ¬ë§¤ì˜í–¥","to_stage":"êµ¬ë§¤", "count":max(0.0, buy)},
    ]

    g = pd.DataFrame(rows).dropna()
    g["count"]  = pd.to_numeric(g["count"], errors="coerce").fillna(0)
    g           = g[g["count"] > 0]
    g["dist"]   = g["to_stage"].map(ORDER) - g["from_stage"].map(ORDER)
    g["kind"]   = np.where(g["dist"]==1, "ì§ì ‘", "ê°„ì ‘")
    g["to_buy"] = (g["to_stage"]=="êµ¬ë§¤")
    kphi        = _flow_scale(seg, mod, loy)
    g["flow_phi"] = g["count"].astype(float) * kphi
    g["segment"] = seg; g["model"] = mod; g["loyalty"] = loy
    return g[[
        "from_stage","to_stage","count","dist","kind","to_buy","flow_phi",
        "segment","model","loyalty"
    ]]

LEVELS_FOR_SANKEY = [
    ("ì „ì²´",               []),
    ("ì„¸ê·¸ë¨¼íŠ¸",           ["segment"]),
    ("ëª¨ë¸",               ["model"]),
    ("ì¶©ì„±ë„",             ["loyalty"]),
    ("ì„¸ê·¸Ã—ëª¨ë¸",          ["segment","model"]),
    ("ì„¸ê·¸Ã—ì¶©ì„±ë„",        ["segment","loyalty"]),
    ("ëª¨ë¸Ã—ì¶©ì„±ë„",        ["model","loyalty"]),
    ("ëª¨ë¸Ã—ì„¸ê·¸Ã—ì¶©ì„±ë„",   ["segment","model","loyalty"]),
]

def build_sankey_cache_from_master(df_master: pd.DataFrame,
                                   collapse_to_buy=True,
                                   collapse_from=("ì„ í˜¸","ì¶”ì²œ","êµ¬ë§¤ì˜í–¥")) -> pd.DataFrame:
    dfm = _ensure_key_cols(df_master).copy()
    out = []
    for _lvl, keys in LEVELS_FOR_SANKEY:
        if not keys:
            seg, mod, loy = "ALL","ALL","ALL"
            row = compose_composite_row(dfm)
            if not row.empty:
                part = _sankey_from_master_row(row, seg, mod, loy)
                part["level"] = _lvl
                out.append(part)
            continue

        for vals, grp in dfm.groupby(keys, dropna=False):
            if not isinstance(vals, tuple): vals = (vals,)
            seg = vals[keys.index("segment")] if "segment" in keys else "ALL"
            mod = vals[keys.index("model")]   if "model"   in keys else "ALL"
            loy = vals[keys.index("loyalty")] if "loyalty" in keys else "ALL"
            row = compose_composite_row(grp)
            if row.empty: 
                continue
            part = _sankey_from_master_row(row, seg, mod, loy)
            part["level"] = _lvl
            out.append(part)

    if not out:
        return pd.DataFrame(columns=[
            "from_stage","to_stage","count","dist","kind","to_buy","flow_phi",
            "segment","model","loyalty","level"
        ])

    full = pd.concat(out, ignore_index=True)
    if collapse_to_buy and not full.empty:
        full = (full.groupby(["level","segment","model","loyalty"], group_keys=False)
                    .apply(lambda g: add_collapsed_to_buy(g, add_from=collapse_from))
                    .reset_index(drop=True))
    return full

def build_sankey_flow_table(
    df_or_tbl: pd.DataFrame | None,
    seg="ALL", mod="ALL", loy="ALL",
    collapse_to_buy=True,
    collapse_from=("ì„ í˜¸","ì¶”ì²œ","êµ¬ë§¤ì˜í–¥")
):
    if df_or_tbl is None or df_or_tbl.empty:
        return pd.DataFrame(columns=["from_stage","to_stage","count","dist","kind","to_buy","flow_phi"])

    s = df_or_tbl.copy()
    low = {str(c).strip().lower(): c for c in s.columns}

    looks_table = (("from_stage" in low and "to_stage" in low) and
                   (("count" in low) or ("flow_phi" in low) or ("bayesian_flow_count" in low)))

    if looks_table:
        t = _sanitize_sankey_table(
            s, seg=seg, mod=mod, loy=loy,
            enforce_single_level=True, drop_overall_if_mixed=True
        )
        if collapse_to_buy:
            t = add_collapsed_to_buy(t, add_from=collapse_from)
        return t

    return _sankey_build_table(
        s, seg=seg, mod=mod, loy=loy,
        collapse_to_buy=collapse_to_buy, collapse_from=collapse_from
    )


def sankey_figure(
    df_sankey: pd.DataFrame | None,
    seg, mod, loy,
    normalize=False, base_stage="ì „ì²´",
    drag=False, show_kind=True,
    table_override: pd.DataFrame | None = None,
):
    # â”€â”€ 0) ë ˆê±°ì‹œ/ì‹¤ìˆ˜ í˜¸í™˜: normalize ìë¦¬ì— DataFrameì´ ë“¤ì–´ì˜¨ ê²½ìš° ë³´ì •
    #    (ìŠ¤ëª¨í¬ í…ŒìŠ¤íŠ¸ì—ì„œ positionalë¡œ overrideê°€ ë“¤ì–´ì˜¤ëŠ” íŒ¨í„´ ë°©ì§€)
    if isinstance(normalize, pd.DataFrame) and table_override is None:
        table_override = normalize
        normalize = False  # ì˜ë¯¸ ì—†ëŠ” ê°’ì´ì—ˆìœ¼ë¯€ë¡œ ì•ˆì „ ê¸°ë³¸ê°’

    # â”€â”€ 1) í…Œì´ë¸” ì†ŒìŠ¤ ì„ íƒ
    if table_override is not None:
        # overrideê°€ rawì—¬ë„ ì•ˆì „í•˜ê²Œ ì •ê·œí™”/ë³´ê°•
        g = _sanitize_sankey_table(table_override, seg=seg, mod=mod, loy=loy)
    else:
        g = build_sankey_flow_table(df_sankey, seg=seg, mod=mod, loy=loy, collapse_to_buy=True)

    if g is None or g.empty:
        return _empty_fig("No Sankey data")

    # â”€â”€ 2) ìƒ‰/ì¸ë±ìŠ¤ ì¤€ë¹„
    idx = {v:i for i,v in enumerate(STAGES)}

    STAGE_COLOR = {
        "ì „ì²´":   COL_STAGE_OVERALL,
        "ë¯¸ì„ í˜¸": COL_STAGE_NONPREF,
        "ì„ í˜¸":   COL_STAGE_PREF,
        "ì¶”ì²œ":   COL_STAGE_REC,
        "êµ¬ë§¤ì˜í–¥": COL_STAGE_INTENT,
        "êµ¬ë§¤":   COL_STAGE_BUY,
    }

    # â˜… ì—¬ê¸° í•œ ì¤„: Sankeyì—ì„œ 'ì „ì²´'ë§Œ ê²€ì •ìœ¼ë¡œ
    STAGE_COLOR["ì „ì²´"] = "#000000"         # ë˜ëŠ” COL_BLACK
    node_colors = [STAGE_COLOR[s] for s in STAGES]

    # âœ… ë…¸ë“œ x ì¢Œí‘œë„ 6ê°œë¡œ
    xs = [0.00, 0.18, 0.34, 0.54, 0.74, 0.94]

    # â”€â”€ 3) ê·¸ë¦¼
    fig = go.Figure()
    fig.add_trace(go.Sankey(
        arrangement=("freeform" if drag else "fixed"),
        valueformat=",.1f", valuesuffix=" Ï†",
    node=dict(
        pad=14, thickness=18, label=STAGES,
        x=xs, y=[0.50]*len(STAGES),
        color=node_colors, line=dict(color="#9aa0a6", width=0.7),
    ),
        link=dict(
            source=[idx[a] for a in g["from_stage"]],
            target=[idx[b] for b in g["to_stage"]],
            value=g["flow_phi"].astype(float).tolist(),
            color=(
                np.where(g["kind"].astype(str)=="ì§ì ‘",
                         hex_to_rgba(COL_LINK_DIRECT,   0.90),
                         hex_to_rgba(COL_LINK_INDIRECT, 0.70))
                if show_kind else [hex_to_rgba(COL_LINK_DIRECT, 0.85)] * len(g)
            ).tolist(),
            customdata=np.stack([
                g["kind"].astype(str).to_numpy(),
                g["dist"].astype(int).to_numpy(),
                g["count"].astype(float).to_numpy(),
            ], axis=-1),
            hovertemplate=(
                "%{customdata[0]} | %{source.label} â†’ %{target.label}"
                "<br>ì í”„: %{customdata[1]}ë‹¨ê³„"
                "<br>ì‹¤ì œìœ ëŸ‰: %{customdata[2]:,} (í‘œì‹œ %{value:,.1f} Ï†)"
                "<extra></extra>"
            ),
        ),
    ))

    if show_kind:
        fig.add_trace(go.Scatter(x=[None], y=[None], mode="markers",
            marker=dict(size=10, color=hex_to_rgba(COL_LINK_DIRECT, 0.90)),   name="ì§ì ‘(ì¸ì ‘)"))
        fig.add_trace(go.Scatter(x=[None], y=[None], mode="markers",
            marker=dict(size=10, color=hex_to_rgba(COL_LINK_INDIRECT, 0.70)), name="ê°„ì ‘(ìŠ¤í‚µ)"))

    base = base_stage if base_stage in STAGES else "ì „ì²´"
    tot_dir = float(g.loc[g["kind"]=="ì§ì ‘", "flow_phi"].sum())
    tot_ind = float(g.loc[g["kind"]=="ê°„ì ‘", "flow_phi"].sum())
    # sankey_figure ëë¶€ë¶„
    fig.update_layout(
        title=f"Journey Sankey Â· ëª¨ë“  ìˆœë°©í–¥(ìŠ¤í‚µ í¬í•¨) Â· ê¸°ì¤€={base}",
        height=390, showlegend=True,
        paper_bgcolor="#fff", plot_bgcolor="#fff",
        font=dict(color="#111"),
        margin=dict(l=10, r=10, t=32, b=64),
    )
    fig.add_annotation(
        x=0, y=-0.20, xref="paper", yref="paper",
        showarrow=False, align="left",
        text=f"ì§ì ‘ {tot_dir:,.1f} Ï† Â· ê°„ì ‘ {tot_ind:,.1f} Ï†",
        font=dict(size=11, color="#444")
    )

    # â†“â†“â†“ ì´ ë„¤ ì¤„ì€ ë°˜ë“œì‹œ í•¨ìˆ˜ ì•ˆìª½(ê°™ì€ ë“¤ì—¬ì“°ê¸° ë ˆë²¨)ì´ì–´ì•¼ í•¨
    fig = apply_dense_grid(fig)  # ê³µí†µ ìŠ¤íƒ€ì¼

    # Sankey ì „ìš©: ì¶• ê°ì¶”ê¸°(ì¹´í…Œì‹œì•ˆ ì¶• ì—†ìŒ)
    fig.update_xaxes(visible=False, showgrid=False, zeroline=False, fixedrange=True)
    fig.update_yaxes(visible=False, showgrid=False, zeroline=False, fixedrange=True)

    return fig


# ==== STAGE COLORS (ì „ì²´â†’ì„ í˜¸â†’ì¶”ì²œâ†’ì˜í–¥â†’êµ¬ë§¤) ====
COL_STAGE_OVERALL = "#C32C2C"  # ë¹¨
COL_STAGE_PREF    = "#D24D3E"  # ì£¼
COL_STAGE_REC     = "#DE937A"  # ë…¸
COL_STAGE_INTENT  = "#D49442"  # ë² (ê³¨ë“œí†¤)
COL_STAGE_BUY     = "#2B8E81"  # ì´ˆfig.update_xaxes
COL_STAGE_NONPREF = "#9CA3AF"  # ë¯¸ì„ í˜¸(íšŒìƒ‰)


def matrix_funnel_figure(row, df_tm, seg, mod, loy, **kwargs):
    # --- 0) ë¡œì»¬ í™•ë¥  ì •ê·œí™” + í´ë¦¬í•‘ ìœ í‹¸ ---
    def _p(x):
        x = _safe_num(x)
        if not np.isfinite(x):
            return np.nan
        # 1.5ë³´ë‹¤ í¬ë©´ 'í¼ì„¼íŠ¸(ì˜ˆ: 23=23%)'ë¡œ ë³´ê³  100ìœ¼ë¡œ ë‚˜ëˆ”
        return x / 100.0 if x > 1.5 else x

    def _clip01(x):
        return np.nan if not np.isfinite(x) else float(min(1.0, max(0.0, x)))

    # 1) ë“œë¡­/ìµœì¢…ìœ¨ í™•ë³´ (í™•ë¥  ì •ê·œí™” + [0,1] í´ë¦¬í•‘)
    d1_raw, d2_raw, d3_raw, full_raw = drops_from_anywhere(row, df_tm, seg, mod, loy)
    d1, d2, d3 = map(_clip01, map(_p, (d1_raw, d2_raw, d3_raw)))
    full_conv  = _p(full_raw)  # ìµœì¢…ìœ¨ì€ ìŒìˆ˜/1ì´ˆê³¼ê°€ ë“¤ì–´ì˜¬ ìˆ˜ ìˆì–´ë„ ì•„ë˜ì—ì„œ ë‹¨ê³„ ë³´ì •ìœ¼ë¡œ ì²˜ë¦¬

    # 2) ê°œë³„ ìŠ¤í…Œì´ì§€ ì„±ê³µë¥  (í™•ë¥  ì •ê·œí™”)
    pref_sr   = _p(row.get("pref_success_rate"))
    rec_sr    = _p(row.get("rec_success_rate"))
    intent_sr = _p(row.get("intent_success_rate"))
    buy_sr    = _p(row.get("buy_success_rate"))

    # 3) ëˆ„ì ìœ¨ ê³„ì‚° (ë“œë¡­ ìš°ì„ , ê²°ì¸¡ ì‹œ í´ë°±)
    overall = 1.0
    pref   = pref_sr

    rec = pref * (1 - d1) if np.isfinite(pref) and np.isfinite(d1) else rec_sr
    intent = rec * (1 - d2) if np.isfinite(rec) and np.isfinite(d2) else intent_sr

    if np.isfinite(intent) and np.isfinite(d3):
        buy = intent * (1 - d3)
    elif np.isfinite(buy_sr):
        buy = buy_sr
    elif np.isfinite(full_conv):
        buy = full_conv
    else:
        buy = intent

    # 3-1) ë‹¨ê³„ ë‹¨ì¡°ê°ì†Œ ë³´ì¥ + 0~1 í´ë¦¬í•‘ (ì—¬ê¸°ì„œ 1.6 ê°™ì€ ê°’ ì°¨ë‹¨)
    seq = [overall,
           _clip01(pref),
           _clip01(rec),
           _clip01(intent),
           _clip01(buy)]
    for i in range(1, len(seq)):
        if np.isfinite(seq[i]) and np.isfinite(seq[i-1]):
            if seq[i] > seq[i-1]:
                seq[i] = seq[i-1]
    overall, pref, rec, intent, buy = seq

    # 4) ë¼ë²¨/ê°’ êµ¬ì„± (ì´í•˜ëŠ” ê¸°ì¡´ ê·¸ëŒ€ë¡œ)
    labels, values = ["ì „ì²´"], [overall]
    if np.isfinite(pref):   labels.append("ì„ í˜¸");     values.append(pref)
    if np.isfinite(rec):    labels.append("ì¶”ì²œ");     values.append(rec)
    if np.isfinite(intent): labels.append("êµ¬ë§¤ì˜í–¥"); values.append(intent)
    if np.isfinite(buy):    labels.append("êµ¬ë§¤");     values.append(buy)

    if len(labels) <= 1:
        return _empty_fig("No Funnel data")

    txtpos = ["inside" if v >= 0.07 else "outside" for v in values]

    color_map = {
        "ì „ì²´":   hex_to_rgba(COL_STAGE_OVERALL, 0.85),
        "ì„ í˜¸":   hex_to_rgba(COL_STAGE_PREF,    0.85),
        "ì¶”ì²œ":   hex_to_rgba(COL_STAGE_REC,     0.85),
        "êµ¬ë§¤ì˜í–¥": hex_to_rgba(COL_STAGE_INTENT,  0.85),
        "êµ¬ë§¤":   hex_to_rgba(COL_STAGE_BUY,     0.85),
    }
    colors = [color_map.get(l, hex_to_rgba(COL_GRAY, 0.85)) for l in labels]

    fig = go.Figure(go.Funnel(
        y=labels,
        x=values,
        name="ëˆ„ì ìœ¨",
        customdata=values,
        textinfo="none",
        texttemplate="%{customdata:.1%}",
        textposition=txtpos,
        hovertemplate="%{label}: %{customdata:.1%}<extra></extra>",
        marker=dict(color=colors, line=dict(width=0.6, color="rgba(0,0,0,0.25)")),
        connector=dict(line=dict(color="rgba(0,0,0,0.25)", width=0.6)),
    ))

    fig.update_layout(
        title="Funnel (ëˆ„ì ìœ¨)",
        height=360,
        margin=dict(l=10, r=10, t=30, b=10),
        paper_bgcolor="#ffffff",
        plot_bgcolor="#ffffff",
    )
    fig.update_xaxes(dtick=_auto_dtick(1.0), tickformat=".0%")
    return apply_dense_grid(fig, x_prob=True)

def survival_curve_figure(row, df_tm, seg, mod, loy):
    d1, d2, d3, _ = drops_from_anywhere(row, df_tm, seg, mod, loy)
    vals = [1.0]
    if np.isfinite(d1): vals.append(vals[-1]*(1-d1))
    if np.isfinite(d2): vals.append(vals[-1]*(1-d2))
    if np.isfinite(d3): vals.append(vals[-1]*(1-d3))
    if len(vals) == 1: return _empty_fig("No Survival data")
    stages = ["Start","ì„ í˜¸","ì¶”ì²œ","êµ¬ë§¤ì˜í–¥","êµ¬ë§¤"][:len(vals)]
    xs = list(range(len(vals)))
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=xs, y=vals, mode="lines+markers",
        line=dict(width=3, color=COL_GRAY), marker=dict(color=COL_GREEN_LITE),
        hovertemplate="ë‹¨ê³„=%{text}<br>ìƒì¡´=%{y:.1%}<extra></extra>", text=stages, name="ìƒì¡´í™•ë¥ "
    ))
    drops = [d1,d2,d3]
    for i, dv in enumerate(drops, start=1):
        if i < len(vals) and np.isfinite(dv):
            fig.add_annotation(x=i-0.5, y=(vals[i-1]+vals[i])/2,
                               text=f"ì‹¤íŒ¨ {dv:.1%}", showarrow=False,
                               font=dict(size=11, color=COL_ORANGE))
    fig.update_layout(height=320, title="ìŠ¤í…Œì´ì§€ ìƒì¡´ ì»¤ë¸Œ",
                      xaxis=dict(tickmode="array", tickvals=xs, ticktext=stages),
                      yaxis=dict(range=[0,1], tickformat=".1%"))
    return apply_dense_grid(fig, y_prob=True)

def waterfall_figure(row, df_tm, seg, mod, loy):
    d1, d2, d3, full = drops_from_anywhere(row, df_tm, seg, mod, loy)

    def _as_prob(p):
        p = _safe_num(p)
        if not np.isfinite(p): return np.nan
        return p/100.0 if p > 1.5 else p

    d1, d2, d3 = map(_as_prob, [d1, d2, d3])
    buy_sr  = _as_prob(row.get("buy_success_rate"))
    intent  = _as_prob(row.get("intent_success_rate"))
    full_in = _as_prob(full)

    # ìµœì¢… êµ¬ë§¤ìœ¨ ë³´ì •
    full = full_in
    if not np.isfinite(full):
        if np.isfinite(buy_sr): full = buy_sr
        elif np.isfinite(intent) and np.isfinite(d3): full = intent * (1.0 - d3)
        elif all(np.isfinite([d1, d2, d3])): full = (1.0 - d1) * (1.0 - d2) * (1.0 - d3)

    # ì ˆëŒ€ ë“œë¡­
    if all(np.isfinite([d1, d2, d3])):
        drop1 = 1.0 * d1
        drop2 = (1.0 - d1) * d2
        drop3 = (1.0 - d1) * (1.0 - d2) * d3
    else:
        drop1 = d1 if np.isfinite(d1) else 0.0
        drop2 = d2 if np.isfinite(d2) else 0.0
        drop3 = d3 if np.isfinite(d3) else 0.0

    # ìµœì¢…ìœ¨ ë¯¸ì§€ì •ì´ë©´ ë“œë¡­ í•©ìœ¼ë¡œ ë³´ì •
    final_rate = float(full) if np.isfinite(full) else max(0.0, 1.0 - drop1 - drop2 - drop3)
    if not any(np.isfinite(v) for v in [drop1, drop2, drop3]) and not np.isfinite(final_rate):
        return _empty_fig("No Waterfall data")

    def _fmt_drop(v): 
        return "" if not np.isfinite(v) else (f"-{v:.1%}" if v >= 1e-6 else "-0.0%")

    # â˜… ì—¬ê¸°ë¶€í„°: 'ì „ì²´ 100%' ë§‰ëŒ€ ì œê±° ë²„ì „
    measures  = ["relative", "relative", "relative", "total"]
    x         = ["ì„ í˜¸â†’ì¶”ì²œ<br>Drop", "ì¶”ì²œâ†’êµ¬ë§¤ì˜í–¥<br>Drop", "êµ¬ë§¤ì˜í–¥â†’êµ¬ë§¤<br>Drop", "êµ¬ë§¤ìœ¨"]
    y         = [-drop1, -drop2, -drop3, final_rate]
    texts     = [_fmt_drop(drop1), _fmt_drop(drop2), _fmt_drop(drop3), f"{final_rate:.1%}"]
    positions = ["inside", "inside", "inside", "outside"]

    fig = go.Figure(go.Waterfall(
        measure=measures, x=x, y=y,
        name="drop-off",
        text=texts, textposition=positions,
        insidetextfont=dict(color="white"),
        outsidetextfont=dict(color="#111"),
        decreasing={"marker":{"color": COL_GRAY_MED}},
        increasing={"marker":{"color": COL_GRAY_MED}},
        totals={"marker":{"color": COL_BLUE_DEEP}},
        connector={"line":{"color":"rgba(0,0,0,0.25)", "width":0.6}},
        cliponaxis=False, constraintext="both"
    ))

    fig.update_layout(
        height=320,
        title="ë“œë¡­ì˜¤í”„ ì›Œí„°í´",
        yaxis_tickformat=".1%",
        xaxis=dict(tickangle=0, automargin=True),
        margin=dict(l=8, r=8, t=30, b=14),  # ì¢Œìš° ì—¬ë°± ì‚´ì§ ë” ì¤„ì„
        uniformtext_minsize=9, uniformtext_mode="hide",
    )

    # ê³µí†µ ìŠ¤íƒ€ì¼ ë¨¼ì €
    fig = apply_dense_grid(fig, y_prob=True)

    # â”€â”€ ì›Œí„°í´ ê°€ë…ì„± íŠœë‹(Apply í›„ ë‹¤ì‹œ ë®ì–´ì“°ê¸°)
    fig.update_layout(
        showlegend=False,   # ë²”ë¡€ ìˆ¨ê²¨ ìƒë‹¨ ê³µê°„ í™•ë³´
        bargap=0.15,        # ë°” ì‚¬ì´ ê°„ê²© ì¶•ì†Œ â†’ ë§‰ëŒ€ê°€ ë‘íˆ¼í•˜ê²Œ
        margin=dict(l=8, r=8, t=30, b=14),
    )
    fig.update_xaxes(automargin=True)

    return fig


def stacked_funnel_figure(row):
    stages = [("ì„ í˜¸", "pref_success_rate"), ("ì¶”ì²œ", "rec_success_rate"),
              ("êµ¬ë§¤ì˜í–¥", "intent_success_rate"), ("êµ¬ë§¤", "buy_success_rate")]
    succ = []; fail = []; labs=[]
    for lab, col in stages:
        p = _safe_num(row.get(col))
        if np.isfinite(p):
            succ.append(p); fail.append(1-p); labs.append(lab)
    if not succ: return _empty_fig("No Funnel data")
    fig = go.Figure()
    fig.add_bar(x=labs, y=succ, name="ì„±ê³µ", text=[f"{v:.1%}" for v in succ], textposition="inside",
                marker_color=COL_GREEN_LITE)
    fig.add_bar(x=labs, y=fail, name="ì‹¤íŒ¨", text=[f"{v:.1%}" for v in fail], textposition="inside",
                marker_color=COL_RED)
    fig.update_layout(barmode="stack", yaxis=dict(range=[0,1], tickformat=".1%"),
                      height=320, title="100% ìŠ¤íƒ í¼ë„ (ì„±ê³µ/ì‹¤íŒ¨)")
    return apply_dense_grid(fig, y_prob=True)

def forest_figure(df_scope: pd.DataFrame):
    if df_scope is None or df_scope.empty:
        return _empty_fig("No Forest data")

    if not {"model", "segment"}.issubset(set(df_scope.columns)):
        return _empty_fig("Need 'model' and 'segment'")

    s = df_scope.copy()

    # ----- 1) ì‚¬ìš©í•  ë‹¨ê³„(ì„±ê³µë¥ ) ì„ íƒ: buy â†’ intent â†’ rec â†’ pref â†’ success_rate â†’ rate
    stage_order = [
        ("buy",    "buy_success_rate"),
        ("intent", "intent_success_rate"),
        ("rec",    "rec_success_rate"),
        ("pref",   "pref_success_rate"),
        ("",       "success_rate"),
        ("",       "rate"),
    ]
    stage = ""
    rate_col = None
    for st, col in stage_order:
        if col in s.columns:
            stage, rate_col = st, col
            break
    if rate_col is None:
        return _empty_fig("No rate column")

    # ----- 2) í‘œë³¸(n) ì»¬ëŸ¼ ì°¾ê¸°(ë‹¨ê³„ë³„ ìš°ì„ , ì—†ìœ¼ë©´ ì¼ë°˜ í‘œë³¸ëª…ìœ¼ë¡œ í´ë°±)
    def _find_n_col(stage_name: str) -> str | None:
        cands = []
        if stage_name:
            cands += [f"{stage_name}_sample_size", f"{stage_name}_n", f"{stage_name}_total"]
        cands += ["sample_size", "n", "N", "total", "count", "nobs", "ë² ì´ìŠ¤ìˆ˜", "í‘œë³¸ìˆ˜", "pref_sample_size"]
        for c in cands:
            if c in s.columns:
                return c
        return None

    n_col = _find_n_col(stage)
    if n_col is None:
        return _empty_fig("No sample size column")

    # ----- 3) ìˆ«ìí™” + ë¹„ìœ¨ ì •ê·œí™”
    s[rate_col] = pd.to_numeric(s[rate_col], errors="coerce")
    s[n_col]    = pd.to_numeric(s[n_col],    errors="coerce")
    s = s.dropna(subset=[rate_col, n_col])
    if s.empty:
        return _empty_fig("No Forest values")

    r = np.where(s[rate_col] > 1.5, s[rate_col] / 100.0, s[rate_col])       # % â†’ ë¹„ìœ¨
    r = np.clip(r, 0.0, 1.0)
    n = np.clip(s[n_col].to_numpy().astype(float), 0.0, np.inf)
    k = np.clip(np.round(r * n), 0.0, n)                                     # ì„±ê³µ ìˆ˜ ì¶”ì •

    # ----- 4) ëª¨ë¸ ë‹¨ìœ„ë¡œ ì§‘ê³„(ì¤‘ë³µ yì¶• ì œê±°)
    agg = (pd.DataFrame({
                "model":   s["model"].astype(str),
                "segment": s["segment"].astype(str),
                "k": k, "n": n
           })
           .groupby("model", as_index=False)
           .agg(k=("k","sum"), n=("n","sum"), seg=("segment", lambda x: x.iloc[0])))

    if agg.empty or not np.isfinite(agg["n"]).any():
        return _empty_fig("No Forest values")

    # ----- 5) Jeffreys 95% CI
    alpha = 0.05
    try:
        from scipy.stats import beta as _beta
        agg["p"]  = (agg["k"] + 0.5) / (agg["n"] + 1.0)
        agg["lo"] = _beta.ppf(alpha/2,     agg["k"] + 0.5, agg["n"] - agg["k"] + 0.5)
        agg["hi"] = _beta.ppf(1 - alpha/2, agg["k"] + 0.5, agg["n"] - agg["k"] + 0.5)
    except Exception:
        try:
            from statsmodels.stats.proportion import proportion_confint
            agg["p"]  = (agg["k"] + 0.5) / (agg["n"] + 1.0)
            lo, hi = proportion_confint(agg["k"], agg["n"], alpha=alpha, method="beta")
            agg["lo"], agg["hi"] = lo, hi
        except Exception:
            # Wilson í´ë°±
            z = 1.959963984540054
            p = agg["k"] / agg["n"]
            denom  = 1 + z*z/agg["n"]
            center = (p + z*z/(2*agg["n"])) / denom
            half   = z*np.sqrt((p*(1-p) + z*z/(4*agg["n"])) / agg["n"]) / denom
            agg["p"]  = p
            agg["lo"] = np.maximum(0.0, center - half)
            agg["hi"] = np.minimum(1.0, center + half)

    use = agg.sort_values("p").reset_index(drop=True)

    # ----- 6) ìƒ‰(ëª¨ë¸ì˜ ìš°ì„¸ ì„¸ê·¸ë¨¼íŠ¸) ì§€ì •
    dom_seg = _model_dominant_segment(df_scope)
    mapped_seg = use["model"].map(dom_seg).fillna(use["seg"])
    colors = mapped_seg.apply(_tier_color_for_segment).tolist()

    err_plus  = (use["hi"] - use["p"]).to_numpy()
    err_minus = (use["p"]  - use["lo"]).to_numpy()

    # ----- 7) í”Œë¡¯
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=use["p"].astype(float),
        y=use["model"].astype(str),
        mode="markers",
        name="ëª¨ë¸",   # â† trace ì´ë¦„ ì§€ì • (trace 0 ì œê±°)
        hovertemplate="%{y}: %{x:.1%}<extra></extra>",
        marker=dict(size=10, color=colors, line=dict(color=COL_BLACK, width=1.6)),
    ))
    fig.update_traces(error_x=dict(
        type="data", symmetric=False,
        array=err_plus, arrayminus=err_minus,
        color=COL_BLACK, thickness=1.2, width=3
    ))
    add_vline_safe(fig, 0.5, line_dash="dot", line_color=COL_BLACK, opacity=0.4)
    fig.update_layout(
        height=320,
        title="í¬ë ˆìŠ¤íŠ¸ í”Œë¡¯ (ëª¨ë¸ ë¹„êµ) â€” 95% CI",
        xaxis=dict(range=[0, 1], dtick=0.1, tickformat=".0%", title="ì„±ê³µë¥ "),
        margin=dict(l=10, r=10, t=30, b=10),
        showlegend=False,   # â† ë‹¨ì¼ íŠ¸ë ˆì´ìŠ¤ë©´ ë²”ë¡€ ìˆ¨ê¹€ (ì›í•˜ë©´ Trueë¡œ)
    )
    return apply_dense_grid(fig, x_prob=True)


def compare_distribution_figure(df_master, seg, mod, loy, stage_label):
    if df_master is None or df_master.empty:
        return _empty_fig("No Ranking data")

    seg = _as_all(seg); mod = _as_all(mod); loy = _as_all(loy)

    stage2lift = {
        "ì„ í˜¸": "pref_lift_vs_galaxy",
        "ì¶”ì²œ": "rec_lift_vs_galaxy",
        "êµ¬ë§¤ì˜í–¥": "intent_lift_vs_galaxy",
        "êµ¬ë§¤": "buy_lift_vs_galaxy",
    }
    lift_col = stage2lift.get(stage_label, "buy_lift_vs_galaxy")
    if lift_col not in df_master.columns:
        return _empty_fig("No lift column")

    # 1) ë¹„êµ ì¶• ê³ ë¥´ê¸°
    candidates = []
    if mod == "ALL": candidates.append("model")
    if seg == "ALL": candidates.append("segment")
    if loy == "ALL": candidates.append("loyalty")

    key = None
    for k in candidates:
        if k in df_master.columns and df_master[k].astype(str).nunique(dropna=True) > 1:
            key = k
            break
    if key is None:
        # fallback: ìœ ë‹ˆí¬ ê°€ì¥ ë§ì€ ì¶•
        avail = [c for c in ["model","segment","loyalty"] if c in df_master.columns]
        if not avail:
            return _empty_fig("No grouping key")
        key = max(avail, key=lambda c: df_master[c].astype(str).nunique(dropna=True))

    # 2) ì „ì²´/ì„ íƒ ì§‘ê³„
    overall = (df_master.groupby(key, as_index=False)
                        .agg({lift_col: "mean"})
                        .rename(columns={lift_col: "ì „ì²´"}))

    scope = df_master.copy()
    if seg != "ALL": scope = scope[scope["segment"].astype(str) == seg]
    if mod != "ALL": scope = scope[scope["model"].astype(str)   == mod]
    if loy != "ALL": scope = scope[scope["loyalty"].astype(str) == loy]

    if scope.empty:
        return _empty_fig("No values")

    selected = (scope.groupby(key, as_index=False)
                      .agg({lift_col: "mean"})
                      .rename(columns={lift_col: "ì„ íƒ"}))

    merged = pd.merge(overall, selected, on=key, how="outer")
    if merged.empty:
        return _empty_fig("No values")

    # 3) ì •ë¦¬: í‚¤ëŠ” ë¬¸ìì—´ë¡œ, ê²°ì¸¡ ìˆ˜ì¹˜ë§Œ 0.0ìœ¼ë¡œ
    merged[key] = merged[key].astype(str)
    for col in ["ì „ì²´", "ì„ íƒ"]:
        if col in merged.columns:
            merged[col] = pd.to_numeric(merged[col], errors="coerce")
    merged[["ì „ì²´","ì„ íƒ"]] = merged[["ì „ì²´","ì„ íƒ"]].fillna(0.0)

    # ì •ë ¬ ìˆœì„œ(ì„ íƒ ì˜¤ë¦„ì°¨ìˆœì´ ê¸°ë³¸, ì „ë¶€ 0ì´ë©´ ì „ì²´ ê¸°ì¤€)
    if (merged["ì„ íƒ"] != 0).any():
        order = merged.sort_values("ì„ íƒ", ascending=True)[key].tolist()
    else:
        order = merged.sort_values("ì „ì²´", ascending=True)[key].tolist()

    base = merged.set_index(key).loc[order]

    # 4) ìƒ‰ìƒ
    vals_sel = base["ì„ íƒ"].to_numpy()
    if key == "model":
        dom_seg = _model_dominant_segment(df_master)
        bar_colors = [_tier_color_for_segment(dom_seg.get(k, "LowEnd")) for k in order]
    else:
        bar_colors = royg_color_for(vals_sel)

    # 5) ê·¸ë¦¼
    fig = go.Figure()
    fig.add_trace(go.Bar(
        x=base["ì „ì²´"], y=order, orientation="h", name="ì „ì²´",
        marker_color="rgba(150,150,150,0.35)"
    ))
    fig.add_trace(go.Bar(
        x=vals_sel, y=order, orientation="h", name="ì„ íƒ",
        marker=dict(color=bar_colors, line=dict(color=COL_GRAY, width=0.5)),
        text=[f"{v:+.1f}" for v in vals_sel], textposition="outside"
    ))
    add_vline_safe(fig, 0, line_dash="dot", line_color=COL_GRAY)
    fig.update_layout(
        barmode="group",
        title=f"{stage_label} ë¦¬í”„íŠ¸ â€” ì „ì²´ vs ì„ íƒ ({key})",
        xaxis_title="Lift vs Galaxy",
        height=320,
        margin=dict(l=10, r=10, t=30, b=10),
        paper_bgcolor="#ffffff", plot_bgcolor="#ffffff"
    )
    return apply_dense_grid(fig)

def bubble_figure(
    df_scope: pd.DataFrame,
    lift_col: str,
    snr_col: str,
    label_top_n: int = 4,
    label_inside: bool = False,
    textfont_size: int = 11
) -> go.Figure:
    # --- ê°€ë“œ ---
    if df_scope is None or df_scope.empty:
        return _empty_fig("No Bubble data")
    if lift_col not in df_scope.columns or snr_col not in df_scope.columns:
        return _empty_fig("No Bubble data")

    s = df_scope.copy()
    s[lift_col] = pd.to_numeric(s[lift_col], errors="coerce")
    s[snr_col]  = pd.to_numeric(s[snr_col],  errors="coerce")
    s["pref_sample_size"] = pd.to_numeric(
        s.get("pref_sample_size", pd.Series(1, index=s.index)),
        errors="coerce"
    ).fillna(1.0)

    key = "model" if ("model" in s.columns and s["model"].notna().any()) else (
          "segment" if "segment" in s.columns else None)
    if key is None:
        return _empty_fig("No Bubble key")

    need_cols = [key, lift_col, snr_col, "pref_sample_size"]
    # ìˆìœ¼ë©´ segmentë¥¼ ì¶”ê°€(ìƒ‰ìƒìš©)
    if "segment" in s.columns and "segment" not in need_cols:
        need_cols.append("segment")

    use = s[need_cols].dropna(subset=[lift_col, snr_col])
    if use.empty:
        return _empty_fig("No Bubble values")

    # ---- ì§‘ê³„ (segment ìœ ë¬´ì— ë”°ë¼ ë¶„ê¸°) ----
    if "segment" in use.columns:
        grp = (use.groupby(key, as_index=False)
                 .agg(x=(lift_col, "mean"),
                      y=(snr_col,  "mean"),
                      n=("pref_sample_size", "sum"),
                      seg=("segment", "first")))
    else:
        grp = (use.groupby(key, as_index=False)
                 .agg(x=(lift_col, "mean"),
                      y=(snr_col,  "mean"),
                      n=("pref_sample_size", "sum")))
        # ìƒ‰ìƒ í•¨ìˆ˜ê°€ ì°¸ì¡°í•˜ëŠ” seg ì»¬ëŸ¼ ë³´ê°•(ì—†ìœ¼ë©´ NaN)
        grp["seg"] = np.nan

    # ---- ìƒ‰ìƒ ----
    dom_seg = _model_dominant_segment(df_scope)
    def _color_for(row):
        if key == "model":
            base_seg = dom_seg.get(str(row[key]), row["seg"])
        else:
            base_seg = row["seg"] if pd.notna(row["seg"]) else row[key]
        return _tier_color_for_segment(base_seg)
    grp["color"] = grp.apply(_color_for, axis=1)

    # ---- ë²„ë¸” í¬ê¸°(âˆšìŠ¤ì¼€ì¼) ----
    n = grp["n"].astype(float).to_numpy()
    if np.isfinite(n).any():
        r = np.sqrt(np.maximum(n, 0))
        r0, r1 = float(np.nanmin(r)), float(np.nanmax(r))
        size = 24.0 if abs(r1 - r0) < 1e-9 else 12 + (r - r0)/(r1 - r0) * 48
    else:
        size = np.full(len(grp), 24.0)

    # ---- ë¼ë²¨ ----
    labels_all = grp[key].astype(str).tolist()
    if label_top_n is None or label_top_n == -1:
        text = labels_all
    elif label_top_n <= 0:
        text = [""] * len(labels_all)
    else:
        top_idx = np.argsort(-grp["n"].to_numpy())[:label_top_n]
        show = set(top_idx.tolist())
        text = [labels_all[i] if i in show else "" for i in range(len(labels_all))]
    hovertext = grp[key].astype(str)

    # ===== ìŠ¹/íŒ¨ ë¶„í•  ê²½ê³„ & ìŒì˜ =====
    x_vals = grp["x"].astype(float).to_numpy()
    y_vals = grp["y"].astype(float).to_numpy()
    x_thr = 0.0 if (np.nanmin(x_vals) < 0 < np.nanmax(x_vals)) else float(np.nanmedian(x_vals))
    y_thr = 2.0 if (np.nanmin(y_vals) <= 2.0 <= np.nanmax(y_vals)) else float(np.nanmedian(y_vals))

    x_min, x_max = float(np.nanmin(x_vals)), float(np.nanmax(x_vals))
    y_min, y_max = float(np.nanmin(y_vals)), float(np.nanmax(y_vals))
    x_pad = (x_max - x_min) * 0.03 if np.isfinite(x_max - x_min) else 0.0
    y_pad = (y_max - y_min) * 0.03 if np.isfinite(y_max - y_min) else 0.0
    x0, x1 = x_min - x_pad, x_max + x_pad
    y0, y1 = y_min - y_pad, y_max + y_pad

    winner_fill = hex_to_rgba("#FDE68A", 0.16)  # ìŠ¹ì(ì—°ë…¸ë‘)
    loser_fill  = hex_to_rgba("#9CA3AF", 0.14)  # íŒ¨ì(ì—°íšŒìƒ‰)

    fig = go.Figure()

    # ìŒì˜ ì˜ì—­(ì•ˆì „ ì‚¬ê°í˜• í—¬í¼ ì‚¬ìš©)
    add_vrect_safe(fig, x0, x_thr, y0=y_thr, y1=y1, fillcolor=loser_fill, layer="below")
    add_vrect_safe(fig, x_thr, x1, y0=y_thr, y1=y1, fillcolor=winner_fill, layer="below")

    # ê²½ê³„ì„ (ì•ˆì „ ë²„ì „)
    add_vline_safe(fig, x_thr, line_dash="dot", line_color="#888", opacity=0.6)
    add_hline_safe(fig, y_thr, line_dash="dot", line_color="#888", opacity=0.6)

    # ---- ë²„ë¸” (âœ… _trace â†’ add_trace) ----
    fig.add_trace(go.Scatter(
        x=grp["x"], y=grp["y"],
        mode="markers+text",
        text=text,
        hovertext=hovertext,
        textposition=("middle center" if label_inside else "top center"),
        textfont=dict(size=textfont_size),
        cliponaxis=False,
        marker=dict(size=size, color=grp["color"], line=dict(color="#111", width=0.7)),
        customdata=grp["n"].astype(float),
        hovertemplate=(
            f"{key}=%{{hovertext}}<br>"
            "Lift=%{x:.1f}<br>"
            "SNR=%{y:.1f}<br>"
            "í‘œë³¸=%{customdata:,}<extra></extra>"
        ),
        name="ëª¨ë¸/ì„¸ê·¸"
    ))

    # ë ˆì´ì•„ì›ƒ
    fig.update_layout(
        title="Lift vs SNR (ë²„ë¸”=í‘œë³¸ìˆ˜)",
        xaxis_title=None,
        yaxis_title="SNR",
        height=320,
        showlegend=False,
        paper_bgcolor="#fff", plot_bgcolor="#fff",
        margin=dict(l=10, r=10, t=26, b=48)
    )
    fig.update_xaxes(title_standoff=18, automargin=True)
    fig.update_yaxes(title_standoff=8,  automargin=True)

    # ê°ì£¼
    foot_y = -0.20
    fig.add_annotation(xref="paper", yref="paper", x=0.00, y=foot_y,
        text="<b>â– </b>", showarrow=False, font=dict(size=11, color="#FDE68A"))
    fig.add_annotation(xref="paper", yref="paper", x=0.035, y=foot_y,
        text="ìŠ¹ì ì˜ì—­ (Liftâ†‘, SNRâ†‘)", showarrow=False, font=dict(size=10, color="#555"), xanchor="left")
    fig.add_annotation(xref="paper", yref="paper", x=0.32, y=foot_y,
        text="<b>â– </b>", showarrow=False, font=dict(size=11, color="#9CA3AF"))
    fig.add_annotation(xref="paper", yref="paper", x=0.355, y=foot_y,
        text="íŒ¨ì ì˜ì—­ (Liftâ†“, SNRâ†‘)", showarrow=False, font=dict(size=10, color="#555"), xanchor="left")
    fig.add_annotation(xref="paper", yref="paper", x=0.67, y=foot_y,
        text="â—‹ ì› í¬ê¸° = í‘œë³¸ìˆ˜(âˆšìŠ¤ì¼€ì¼)", showarrow=False, font=dict(size=10, color="#666"), xanchor="left")

    # ê³µí†µ ìŠ¤íƒ€ì¼ í›„ ì¬ê³ ì •
    fig = apply_dense_grid(fig)
    fig.update_layout(height=320, margin=dict(l=10, r=10, t=26, b=48), showlegend=False, xaxis_title=None)
    fig.update_xaxes(title_standoff=18, automargin=True)
    fig.update_yaxes(title_standoff=8,  automargin=True)

    # xì¶• ì œëª©ì„ annotationìœ¼ë¡œ
    fig.add_annotation(
        text="Lift vs Galaxy",
        xref="x domain", yref="paper",
        x=1, y=-0.10,
        xanchor="right", yanchor="top",
        showarrow=False,
        font=dict(size=12)
    )

    return fig

def ppc_purchase_overlay_figure(row: pd.Series, m: int | None = None, draws: int = 6000) -> go.Figure:
    """ê´€ì¸¡ êµ¬ë§¤ìœ¨ê³¼ Posterior(ë² íƒ€) & Posterior Predictive(ë² íƒ€-ì´í•­) ì˜¤ë²„ë ˆì´."""
    # ê´€ì¸¡ì¹˜
    n = _pick_sample_for_stage(row, "buy")
    if n <= 0:
        n = _safe_int0(row.get("pref_sample_size"))
    p_obs = _safe_num(row.get("buy_success_rate"))
    if not np.isfinite(p_obs):
        return _empty_fig("No PPC data")
    p_obs = float(np.clip(p_obs/100.0 if p_obs > 1.5 else p_obs, 0.0, 1.0))
    k_obs = int(np.clip(round(p_obs * max(n, 1)), 0, max(n, 1)))
    if m is None:
        m = n

    # Posterior (Jeffreys prior: Beta(0.5,0.5))
    a, b = k_obs + 0.5, (n - k_obs) + 0.5
    p = np.random.beta(a, b, size=draws)

    # Posterior predictive (ìƒˆ í‘œë³¸ mê°œ ê´€ì¸¡ ì‹œ ë¹„ìœ¨)
    m = max(int(m), 1)
    k_pred = np.random.binomial(m, p)
    rate_pred = k_pred / m

    # 95% HDI
    lo, hi = np.quantile(p, [0.025, 0.975])

    fig = go.Figure()
    fig.add_histogram(
        x=p, nbinsx=60, histnorm="probability density",
        name="Posterior p", marker_color=hex_to_rgba("#9CA3AF", 0.45), opacity=0.55
    )
    fig.add_histogram(
        x=rate_pred, nbinsx=60, histnorm="probability density",
        name=f"PPC n={m:,}", marker_color=hex_to_rgba(COL_STAGE_BUY, 0.55), opacity=0.55
    )

    # ê´€ì¸¡ì¹˜/êµ¬ê°„ í‘œì‹œ
    add_vline_safe(fig, p_obs, line_color="#111", line_width=2, opacity=0.9)
    fig.add_vrect(x0=lo, x1=hi, fillcolor=hex_to_rgba("#60A5FA", 0.18), line_width=0)

    # â† í•µì‹¬: ë²”ë¡€ë¥¼ ì•„ë˜ë¡œ(ë„ë©´ ë°–) ë³´ë‚´ê³  ì•„ì£¼ ì‘ê²Œ
    fig.update_layout(
        barmode="overlay",
        title="PPC(êµ¬ë§¤ìœ¨) â€” Posterior & Posterior Predictive",
        height=320,
        margin=dict(l=10, r=10, t=30, b=64),   # ë°”ë‹¥ ì—¬ë°± í™•ë³´
        showlegend=True,
        legend=dict(
            orientation="h",
            y=-0.22, yanchor="top",   # í”Œë¡¯ ì•„ë˜ìª½, ë„ë©´ ë°–
            x=0.0,   xanchor="left",
            font=dict(size=9),
            itemsizing="constant",
            itemwidth=30
        )
    )
    fig.update_xaxes(range=[0, 1], tickformat=".0%", title="êµ¬ë§¤ìœ¨")
    fig.update_yaxes(title="ë°€ë„")
    return apply_dense_grid(fig, x_prob=True)

percent1 = FormatTemplate.percentage(1)
num1 = Format(precision=1, scheme=Scheme.fixed)

CARD_STYLE = {
    "background":"white","border":"1px solid #eaeaea","borderRadius":"14px",
    "padding":"14px","boxShadow":"0 2px 10px rgba(0,0,0,0.04)"
}

# (ì¶”ê°€) KPI ì „ìš© ì¹´ë“œ â€” í•˜ëŠ˜ìƒ‰ ë°°ê²½
KPI_CARD_STYLE = {
    **CARD_STYLE,
    "background": "#EAF2FF",
    "border": "1px solid #d6e4ff"
}

ROW2_CARD_H  = 360
ROW2_GRAPH_H = 320

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ app.layout êµì²´ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app.layout = html.Div(
    [
        dcc.Store(id="store-master"),
        dcc.Store(id="store-tm"),
        dcc.Store(id="store-sankey"),
        dcc.Store(id="store-overall"),
        dcc.Store(id="store-mod-opts"),

        # Sankey ë“œë˜ê·¸ í† ê¸€ + ì¸í„°ë™ì…˜ ë¡œê·¸
        html.Div(
            [
                dcc.Checklist(
                    id="sankey-drag",
                    options=[{"label": " Sankey ë“œë˜ê·¸ í—ˆìš©", "value": "drag"}],
                    value=[],
                    inputStyle={"marginRight": "6px"},
                    style={"fontSize": "12px", "color": "#555"},
                ),
                html.Div(id="interact-msg", style={"marginTop": "6px","fontSize": "12px","color": "#444"}),
            ],
            style={"display":"flex","justifyContent":"space-between","alignItems":"center","padding":"0 16px 8px"},
        ),

        # ìƒë‹¨ ë°”
        html.Div(
            [
                html.Div("Bayesian Journey Dashboard", style={"fontWeight":"700","fontSize":"18px"}),
                html.Div(
                    [
                        dcc.Input(id="excel-path", value=DEFAULT_PATH, placeholder="Excel ê²½ë¡œ",
                                  style={"width":"520px","marginRight":"8px"}),
                        html.Button("Load", id="load-btn", n_clicks=0, className="btn", style={"marginRight":"8px"}),
                    ],
                    style={"display":"flex","alignItems":"center"},
                ),
            ],
            style={"display":"flex","justifyContent":"space-between","alignItems":"center",
                   "padding":"12px 16px","borderBottom":"1px solid #eee","position":"sticky",
                   "top":"0","background":"#fafafa","zIndex":10},
        ),

        html.Div(id="status-msg", style={"padding":"8px 16px","color":"#555","fontSize":"12px"}),

        # í•„í„°
        html.Div(
            [
                html.Div([html.Label("Segment", style={"fontWeight":"600"}),
                          dcc.Dropdown(id="dd-seg", options=[], value="ALL", clearable=True)],
                         style={"flex":"1","minWidth":"220px","marginRight":"8px"}),
                html.Div([html.Label("Model",   style={"fontWeight":"600"}),
                          dcc.Dropdown(id="dd-mod", options=[], value="ALL", clearable=True)],
                         style={"flex":"1","minWidth":"220px","marginRight":"8px"}),
                html.Div([html.Label("Loyalty", style={"fontWeight":"600"}),
                          dcc.Dropdown(id="dd-loy", options=[], value="ALL", clearable=True)],
                         style={"flex":"1","minWidth":"220px"}),
            ],
            style={"display":"flex","gap":"8px","padding":"12px 16px"},
        ),

        # KPI
        html.Div(
            [
                html.Div([html.Div("í‘œë³¸ ìˆ˜", style={"color":"#888","fontSize":"12px"}),
                          html.H3(id="kpi-sample", style={"margin":"4px 0 0"})], style=KPI_CARD_STYLE),
                html.Div([html.Div("ìµœì¢… êµ¬ë§¤ìœ¨ (Î” í¬í•¨)", style={"color":"#888","fontSize":"12px"}),
                          html.H3(id="ins-final", style={"margin":"4px 0 0"})], style=KPI_CARD_STYLE),
                html.Div([html.Div("ìµœëŒ€ ë“œë¡­", style={"color":"#888","fontSize":"12px"}),
                          html.H3(id="ins-drop", style={"margin":"4px 0 0","fontSize":"18px"})], style=KPI_CARD_STYLE),
                html.Div([html.Div("ë¶ˆí™•ì‹¤ì„± (95% HDI í­)", style={"color":"#888","fontSize":"12px"}),
                          html.H3(id="ins-uncert", style={"margin":"4px 0 0"})], style=KPI_CARD_STYLE),
            ],
            style={"display":"grid","gridTemplateColumns":"repeat(4,1fr)","gap":"12px","padding":"0 16px 12px"},
        ),

        # ìˆ¨ê¹€ KPI(í˜¸í™˜)
        html.Div([html.H3(id="kpi-buy-success"), html.H3(id="kpi-buy-fail")], style={"display":"none"}),

        # Row 1: Sankey + ì „ì´ í¼ë„ + (ì›Œí„°í´/PPC íƒ­)
        html.Div(
            [
                html.Div(dcc.Graph(id="fig-sankey", config=GRAPH_CONFIG, style={"height":"400px"}),
                         style={**CARD_STYLE, "height":"440px"}),

                html.Div(dcc.Graph(id="fig-matrix", config=GRAPH_CONFIG, style={"height":"400px"}),
                         style={**CARD_STYLE, "height":"440px"}),

                html.Div(
                    [
                        dcc.Tabs(
                            id="tab-right", value="waterfall",
                            children=[
                                dcc.Tab(label="ì›Œí„°í´", value="waterfall"),
                                dcc.Tab(label="PPC(êµ¬ë§¤ìœ¨)", value="ppc"),
                            ],
                            style={"marginBottom":"6px"},
                        ),
                        dcc.Graph(id="fig-right", config=GRAPH_CONFIG, style={"height":"400px"}),
                    ],
                    style={**CARD_STYLE, "height":"440px"},
                ),
            ],
            style={
                "display":"grid",
                "gridTemplateColumns":"1.3fr 1fr 1.5fr",   # â† ì˜¤ë¥¸ìª½ ì¹´ë“œ ë„“í˜
                "gap":"18px",
                "padding":"30px 30px 30px", "marginBottom":"36px"
            },
        ),

        # Row 2: ìŠ¤í…Œì´ì§€ ë¦¬í”„íŠ¸ + í¬ë ˆìŠ¤íŠ¸ + ë²„ë¸”
        html.Div(
            [
                html.Div(
                    [
                        html.Div(
                            [
                                html.Span("Stage", style={"fontSize":"12px","color":"#666","marginRight":"8px"}),
                                dcc.Dropdown(
                                    id="dd-stage-rank",
                                    options=[{"label": v, "value": v} for v in ["ì„ í˜¸","ì¶”ì²œ","êµ¬ë§¤ì˜í–¥","êµ¬ë§¤"]],
                                    value="êµ¬ë§¤", clearable=False,
                                    style={"width":"140px","fontSize":"12px"},
                                ),
                            ],
                            style={"display":"flex","justifyContent":"flex-end","alignItems":"center","marginBottom":"6px"},
                        ),
                        dcc.Graph(id="fig-stage-rank", config=GRAPH_CONFIG, style={"height":"380px"}),
                    ],
                    style={**CARD_STYLE, "height":"420px","overflow":"hidden"},
                ),

                html.Div(dcc.Graph(id="fig-forest", config=GRAPH_CONFIG, style={"height":"380px"}),
                         style={**CARD_STYLE, "height":"420px","overflow":"hidden"}),

                html.Div(dcc.Graph(id="fig-bubble", config=GRAPH_CONFIG, style={"height":"380px"}),
                         style={**CARD_STYLE, "height":"420px","overflow":"hidden"}),
            ],
            style={"display":"grid","gridTemplateColumns":"1fr 1fr 1fr","gap":"18px","padding":"30px 30px 30px", "marginTop":"36px"},
        ),


        # ìˆ¨ê¹€ ê·¸ë˜í”„
        html.Div(
            [
                dcc.Graph(id="fig-survival", config=GRAPH_CONFIG),
                dcc.Graph(id="fig-funnel",   config=GRAPH_CONFIG),
            ],
            style={"display":"none"},
        ),

        # ìƒì„¸ í…Œì´ë¸”
        html.Div(
            [
                html.H4("ìƒì„¸ ë©”íŠ¸ë¦­", style={"margin":"0 0 8px 0"}),
                dash_table.DataTable(
                    id="metrics-table",
                    columns=[
                        {"name": "ë‹¨ê³„",        "id": "ë‹¨ê³„"},
                        {"name": "ë² ì´ìŠ¤ìˆ˜",    "id": "ë² ì´ìŠ¤ìˆ˜",    "type": "numeric",
                         "format": Format(precision=0, scheme=Scheme.fixed)},
                        {"name": "ì„±ê³µí™•ë¥ ",    "id": "ì„±ê³µí™•ë¥ ",    "type": "numeric", "format": percent1},
                        {"name": "ì‹¤íŒ¨í™•ë¥ ",    "id": "ì‹¤íŒ¨í™•ë¥ ",    "type": "numeric", "format": percent1},
                        {"name": "í•˜í•œ",        "id": "í•˜í•œ",        "type": "numeric", "format": percent1},
                        {"name": "ìƒí•œ",        "id": "ìƒí•œ",        "type": "numeric", "format": percent1},
                        {"name": "íŒì •",        "id": "íŒì •"},
                        {"name": "í‰ê°€ë“±ê¸‰",    "id": "í‰ê°€ë“±ê¸‰"},
                        {"name": "SNR",         "id": "SNR",         "type": "numeric", "format": num1},
                        {"name": "Lift",        "id": "Lift",        "type": "numeric", "format": num1},
                        {"name": "rawí‰ê· ",     "id": "rawí‰ê· ",     "type": "numeric", "format": percent1},
                        {"name": "rawí‘œì¤€í¸ì°¨", "id": "rawí‘œì¤€í¸ì°¨", "type": "numeric", "format": percent1},
                    ],
                    data=[],
                    page_size=10,
                    style_table={"overflowX":"auto"},
                    style_cell={
                        "fontFamily":"Noto Sans KR, Arial, sans-serif",
                        "fontSize":"12px",
                        "padding":"6px",
                    },
                    style_header={"fontWeight":"bold"},
                    style_data_conditional=[
                        {"if": {"column_id": "ë² ì´ìŠ¤ìˆ˜"},     "textAlign": "right"},
                        {"if": {"column_id": "ì„±ê³µí™•ë¥ "},     "textAlign": "right"},
                        {"if": {"column_id": "ì‹¤íŒ¨í™•ë¥ "},     "textAlign": "right"},
                        {"if": {"column_id": "í•˜í•œ"},         "textAlign": "right"},
                        {"if": {"column_id": "ìƒí•œ"},         "textAlign": "right"},
                        {"if": {"column_id": "SNR"},          "textAlign": "right"},
                        {"if": {"column_id": "Lift"},         "textAlign": "right"},
                        {"if": {"column_id": "rawí‰ê· "},      "textAlign": "right"},
                        {"if": {"column_id": "rawí‘œì¤€í¸ì°¨"},  "textAlign": "right"},
                        {"if": {"row_index": "odd"}, "backgroundColor": "#fafafa"},
                    ],
                ),
            ],
            style={**CARD_STYLE, "margin":"18px 16px 24px"},
        ),
    ],
    style={"background":"#f6f7fb","minHeight":"100vh"},
)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ app.layout êµì²´ ë â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# ===================== ì½œë°±: Load =====================
@app.callback(
    Output("store-master","data"),
    Output("store-tm","data"),
    Output("store-sankey","data"),
    Output("store-overall","data"),
    Output("dd-seg","options"),
    Output("dd-seg","value"),
    Output("store-mod-opts","data"),
    Output("dd-loy","options"),
    Output("dd-loy","value"),
    Output("status-msg","children"),
    Input("load-btn","n_clicks"),
    State("excel-path","value"),
    prevent_initial_call=True
)
def on_load(n, path):
    try:
        exists = os.path.exists(path)
        size   = (os.path.getsize(path) if exists else 0)

        # 1) ì—‘ì…€ ë¡œë“œ
        df_master, df_tm, df_sankey, overall, seg_opts, mod_opts_all, loy_opts, dbg = load_excel(path)

        # 2) ë§ˆìŠ¤í„°ë¡œë¶€í„° ëª¨ë“  ì¡°í•© Sankey ìºì‹œ í•©ì„±
        df_sankey_syn = build_sankey_cache_from_master(df_master, collapse_to_buy=True)

        # 3) ìƒíƒœ ë©”ì‹œì§€(ìºì‹œ í–‰ìˆ˜ í¬í•¨)
        status = (f"âœ… ë¡œë“œ ì™„ë£Œ | path={path} (exists={exists}, size={size:,} bytes) | "
                  f"engine={dbg.get('engine')} | sheets={dbg.get('sheets')} | matched={dbg.get('matched')} | "
                  f"sankey_cache={len(df_sankey_syn):,} rows")

        # 4) ë¦¬í„´: ì„¸ ë²ˆì§¸(store-sankey)ì— ìºì‹œë¥¼ ë„£ëŠ”ë‹¤
        return (
            df_master.to_json(date_format="iso", orient="split"),
            df_tm.to_json(date_format="iso", orient="split"),
            df_sankey_syn.to_json(date_format="iso", orient="split"),  # â¬… ì—¬ê¸°!
            json.dumps(overall),
            [{"label":v, "value":v} for v in seg_opts], "ALL",
            json.dumps(mod_opts_all),
            [{"label":v, "value":v} for v in loy_opts], "ALL",
            status
        )
    except Exception as e:
        err = f"âŒ LOAD ERROR: {type(e).__name__}: {e}"
        print("LOAD ERROR TRACE:\n", traceback.format_exc())
        return None, None, None, None, [], None, None, [], None, err


# ì„¸ê·¸ë¨¼íŠ¸ ë³€ê²½ ì‹œ ëª¨ë¸ ì˜µì…˜ ì—…ë°ì´íŠ¸
@app.callback(
    Output("dd-mod","options"),
    Output("dd-mod","value"),
    Input("dd-seg","value"),
    State("store-master","data"),
    State("store-mod-opts","data"),
)
def on_seg_change(seg, js_master, js_allmods):
    if not js_master or not js_allmods:
        return [], None
    df_master = pd.read_json(js_master, orient="split")
    seg_val = _as_all(seg)
    if seg_val!="ALL":
        mods = ["ALL"] + sorted([str(v) for v in df_master[df_master["segment"].astype(str)==seg_val]["model"].dropna().astype(str).unique().tolist() if str(v)!="ALL"])
    else:
        mods = json.loads(js_allmods)
    return [{"label":v,"value":v} for v in mods], "ALL"

@app.callback(
    Output("interact-msg","children"),
    Input("fig-sankey","clickData"),
    Input("fig-matrix","relayoutData"),
    Input("fig-right","relayoutData"),  
    Input("fig-stage-rank","selectedData"),
    Input("fig-forest","selectedData"),
    Input("fig-bubble","selectedData"),
    prevent_initial_call=True
)
def on_interact(sankey_click, matrix_relayout, wf_relayout, rank_sel, forest_sel, bubble_sel):
    ctx = dash.callback_context
    if not ctx.triggered:
        return dash.no_update

    tid = ctx.triggered[0]["prop_id"]  # e.g. "fig-bubble.selectedData"
    comp, prop = tid.split(".")
    payload = ctx.triggered[0]["value"]

    if prop == "clickData" and payload:
        pt = (payload.get("points") or [{}])[0]
        label = pt.get("label") or f"{pt.get('sourceLabel','?')}â†’{pt.get('targetLabel','?')}"
        return f"ğŸ–± {comp}: {label} í´ë¦­"
    if prop == "selectedData" and payload:
        n = len(payload.get("points", []))
        return f"ğŸ” {comp}: {n}ê°œ ì„ íƒ"
    if prop == "relayoutData" and payload:
        keys = ", ".join(list(payload.keys())[:3])
        return f"ğŸ§­ {comp}: ë·° ë³€ê²½({keys}...)"

    return dash.no_update

# update_all ìœ„ìª½(ê°™ì€ íŒŒì¼)ì— ì¶”ê°€
def _slice_sankey_cache_by_choice(df, seg, mod, loy):
    if df is None or df.empty:
        return pd.DataFrame()
    sub = df.copy()
    if "segment" in sub.columns and seg != "ALL":
        sub = sub[(sub["segment"].astype(str) == seg) | sub["segment"].isna() | (sub["segment"].astype(str) == "ALL")]
    if "model" in sub.columns and mod != "ALL":
        sub = sub[(sub["model"].astype(str) == mod) | sub["model"].isna() | (sub["model"].astype(str) == "ALL")]
    if "loyalty" in sub.columns and loy != "ALL":
        sub = sub[(sub["loyalty"].astype(str) == loy) | sub["loyalty"].isna() | (sub["loyalty"].astype(str) == "ALL")]
    if "level" in sub.columns:
        for lv in LVL_PRIORITY:
            cand = sub[sub["level"].astype(str) == lv]
            if not cand.empty:
                return cand.copy()
    return sub


    # ë ˆë²¨ ìš°ì„ ìˆœìœ„(ê°€ì¥ ì„¸ë¶„í™”ëœ ê²ƒë¶€í„°)ë¡œ í•˜ë‚˜ë§Œ ë‚¨ê¸°ê¸°
    if "level" in sub.columns:
        for lv in LVL_PRIORITY:
            cand = sub[sub["level"].astype(str) == lv]
            if not cand.empty:
                return cand.copy()
    return sub

def _read_df_store(js):
    if not js:
        return pd.DataFrame()
    # ì´ë¯¸ dict/objectë¡œ ë“¤ì–´ì˜¤ë©´ ì‹œë„
    if isinstance(js, dict):
        if {"columns","data"}.issubset(js.keys()):
            return pd.DataFrame(js["data"], columns=js["columns"])
        try:
            return pd.DataFrame(js)
        except Exception:
            return pd.DataFrame()
    # ë¬¸ìì—´ì´ë©´ ìš°ì„  split â†’ ì‹¤íŒ¨ ì‹œ ì¼ë°˜ json í•´ì„
    if isinstance(js, str):
        try:
            return pd.read_json(io.StringIO(js), orient="split")
        except Exception:
            try:
                obj = json.loads(js)
                if isinstance(obj, dict) and {"columns","data"}.issubset(obj.keys()):
                    return pd.DataFrame(obj["data"], columns=obj["columns"])
                elif isinstance(obj, list):
                    return pd.DataFrame(obj)
                elif isinstance(obj, dict):
                    # overall ê°™ì€ dictê°€ ì˜¤ë©´ DFë¡œ ë§Œë“¤ì§€ ì•Šê³  ë¹ˆ DF ë°˜í™˜
                    return pd.DataFrame()
            except Exception:
                return pd.DataFrame()
    return pd.DataFrame()

def _read_overall(js_overall):
    if not js_overall:
        return {}
    if isinstance(js_overall, dict):
        return js_overall
    try:
        return json.loads(js_overall)
    except Exception:
        return {}

# ===================== ì½œë°±: ëŒ€ì‹œë³´ë“œ ê³„ì‚° =====================
@app.callback(
    Output("kpi-sample","children"),
    Output("kpi-buy-success","children"),
    Output("kpi-buy-fail","children"),
    Output("ins-final","children"),
    Output("ins-drop","children"),
    Output("ins-uncert","children"),
    Output("metrics-table","data"),
    Output("fig-sankey","figure"),
    Output("fig-matrix","figure"),
    #Output("fig-simfan","figure"),
    Output("fig-bubble","figure"),
    Output("fig-stage-rank","figure"),
    Output("fig-survival","figure"),
    Output("fig-right","figure"),  
    # Output("fig-waterfall","figure"),
    Output("fig-funnel","figure"),
    Output("fig-forest","figure"),
    Input("dd-seg","value"),
    Input("dd-mod","value"),
    Input("dd-loy","value"),
    Input("sankey-drag","value"),
    Input("dd-stage-rank","value"),
    Input("tab-right","value"),            # â† ì¶”ê°€
    Input("store-master","data"),
    Input("store-tm","data"),
    Input("store-sankey","data"),
    Input("store-overall","data"),
)

def update_all(seg, mod, loy, drag_val, stage_label, tab_right,
               js_master, js_tm, js_sankey, js_overall=None):
    # ê¸°ë³¸ê°’ ë³´ì •
    seg = _as_all(seg); mod = _as_all(mod); loy = _as_all(loy)
    if not isinstance(stage_label, str) or not stage_label:
        stage_label = "êµ¬ë§¤"
    empty = _empty_fig("Load data first")

    # ê°€ë“œ: ë§ˆìŠ¤í„° ì—†ìœ¼ë©´ 15ê°œ í…œí”Œë¦¿ ë¦¬í„´
    if not js_master:
        return (
            "â€“", "â€“", "â€“",   # kpi-sample, kpi-buy-success, kpi-buy-fail
            "â€“", "â€“", "â€“",   # ins-final, ins-drop, ins-uncert
            [],              # metrics-table.data
            empty, empty,    # fig-sankey, fig-matrix
            empty, empty,    # fig-bubble, fig-stage-rank
            empty, empty,    # fig-survival, fig-right
            empty,           # fig-funnel
            empty            # fig-forest
        )

    js_sankey, js_overall, _ = _maybe_swap_sankey_overall(js_sankey, js_overall)

    try:
        # 0) sankey/overall ë’¤ë°”ë€œ ìë™ êµì •
        js_sankey, js_overall, _ = _maybe_swap_sankey_overall(js_sankey, js_overall)

        # 1) ìŠ¤í† ì–´ ì½ê¸°(ì•ˆì „)
        df_master = _read_df_store(js_master)
        df_tm     = _read_df_store(js_tm)
        df_sankey = _read_df_store(js_sankey)
        overall   = _read_overall(js_overall)

        # 2) ì„ íƒ/ìŠ¤ì½”í”„
        row_pick = pick_row_for(df_master, seg, mod, loy)
        scope = df_master.copy()
        if seg!="ALL": scope = scope[scope["segment"].astype(str)==seg]
        if mod!="ALL": scope = scope[scope["model"].astype(str)==mod]
        if loy!="ALL": scope = scope[scope["loyalty"].astype(str)==loy]

        # ì§‘ê³„í–‰ìœ¼ë¡œ ê²°ì¸¡ ë³´ê°•
        row_agg = compose_composite_row(scope)
        rowd = {k: row_pick[k] for k in row_pick.index}

        def _safe_num_or_nan(x):
            try:
                fx = float(x)
                return fx if np.isfinite(fx) else np.nan
            except Exception:
                return np.nan

        def coalesce_into(dst_dict, src_series, cols):
            for c in cols:
                va = _safe_num_or_nan(dst_dict.get(c))
                if np.isnan(va):
                    dst_dict[c] = (src_series.get(c) if isinstance(src_series, pd.Series) else np.nan)

        core_cols = [
            "pref_sample_size",
            "pref_success_rate","pref_ci_lower","pref_ci_upper",
            "rec_success_rate","rec_ci_lower","rec_ci_upper",
            "intent_success_rate","intent_ci_lower","intent_ci_upper",
            "buy_success_rate","buy_ci_lower","buy_ci_upper",
            "bayesian_dropout_pref_to_rec","bayesian_dropout_rec_to_intent","bayesian_dropout_intent_to_buy",
            "bayesian_full_conversion",
            "pref_snr","rec_snr","intent_snr","buy_snr",
            "pref_lift_vs_galaxy","rec_lift_vs_galaxy","intent_lift_vs_galaxy","buy_lift_vs_galaxy",
        ]
        coalesce_into(rowd, row_agg, core_cols)
        row = pd.Series(rowd)

        # 3) KPI/í…Œì´ë¸”
        tbl = metrics_table_row(row)

        def _face(val, good, soso, reverse=False):
            if not np.isfinite(val): return "â”"
            v = (1 - val) if reverse else val
            return "ğŸŸ¢" if v >= good else ("ğŸŸ¡" if v >= soso else "ğŸ”´")

        GOOD_P, SOSO_P = 0.55, 0.45
        GOOD_DROP, SOSO_DROP = 0.20, 0.35
        GOOD_W, SOSO_W = 0.08, 0.12

        sample = _safe_int0(row.get("pref_sample_size"))
        kpi_sample_text = f"ğŸ“Š {sample:,}"

        buy_p = _safe_num(row.get("buy_success_rate"))
        buy_s = (f"{buy_p:.1%}" if np.isfinite(buy_p) else "N/A")
        buy_f = (f"{(1-buy_p):.1%}" if np.isfinite(buy_p) else "N/A")

        overall_buy = _safe_num(overall.get("buy_mean"))
        delta = (buy_p - overall_buy) if (np.isfinite(buy_p) and np.isfinite(overall_buy)) else np.nan
        face_final = _face(buy_p, GOOD_P, SOSO_P, reverse=False)
        ins_final = (f"{face_final} ì„±ê³µ {buy_s} / ì‹¤íŒ¨ {buy_f} (vs ì „ì²´ {delta:+.1%}p)"
                     if np.isfinite(delta) else f"{face_final} ì„±ê³µ {buy_s} / ì‹¤íŒ¨ {buy_f}")

        d1, d2, d3, _ = drops_from_anywhere(row, df_tm, seg, mod, loy)
        drops = [v for v in [d1, d2, d3] if np.isfinite(v)]
        dmax = max(drops) if drops else np.nan
        face_drop = _face(dmax, GOOD_DROP, SOSO_DROP, reverse=True)
        ins_drop = f"{face_drop} " + biggest_drop_text_by_sources(row, df_tm, seg, mod, loy)

        def _widest_hdi(r):
            pick = []
            for stage, lo_col, hi_col in [("ì„ í˜¸","pref_ci_lower","pref_ci_upper"),
                                          ("ì¶”ì²œ","rec_ci_lower","rec_ci_upper"),
                                          ("êµ¬ë§¤ì˜í–¥","intent_ci_lower","intent_ci_upper"),
                                          ("êµ¬ë§¤","buy_ci_lower","buy_ci_upper")]:
                lo = _safe_num(r.get(lo_col)); hi = _safe_num(r.get(hi_col))
                if np.isfinite(lo) and np.isfinite(hi):
                    pick.append((stage, max(0.0, hi - lo)))
            return max(pick, key=lambda x: x[1]) if pick else (None, np.nan)

        stage_w, width_w = _widest_hdi(row)
        face_unc = _face(width_w, GOOD_W, SOSO_W, reverse=True)
        ins_uncert = "ë°ì´í„° ì—†ìŒ" if stage_w is None else f"{face_unc} {stage_w} ë‹¨ê³„ {width_w*100:.1f}%p"

        # 4) Sankey (ìºì‹œ ì •ê·œí™” â†’ ë³´ê°•)
        g_for_sankey = build_sankey_flow_table(df_sankey, seg=seg, mod=mod, loy=loy, collapse_to_buy=True)
        if g_for_sankey is None or g_for_sankey.empty:
            # ì™„ì „ ë¹„ë©´ í˜„ì¬ rowë¡œ ì¦‰ì„ í•©ì„±
            g_for_sankey = _sankey_from_master_row(row, seg, mod, loy)
            g_for_sankey = add_collapsed_to_buy(g_for_sankey, add_from=("ì„ í˜¸","ì¶”ì²œ","êµ¬ë§¤ì˜í–¥"))

        fig_sankey = sankey_figure(
            df_sankey=None,
            seg=seg, mod=mod, loy=loy,
            drag=("drag" in (drag_val or [])),
            table_override=g_for_sankey
        )

        # 5) ë‚˜ë¨¸ì§€ ê·¸ë˜í”„
        fig_matrix     = matrix_funnel_figure(row, df_tm, seg, mod, loy)
        lift_col       = "buy_lift_vs_galaxy" if "buy_lift_vs_galaxy" in scope.columns else "pref_lift_vs_galaxy"
        snr_col        = "buy_snr"            if "buy_snr"            in scope.columns else "pref_snr"
        fig_bubble     = bubble_figure(scope, lift_col, snr_col)
        fig_stage_rank = compare_distribution_figure(df_master, seg, mod, loy, stage_label)
        fig_survival   = survival_curve_figure(row, df_tm, seg, mod, loy)
        fig_funnel     = stacked_funnel_figure(row)
        fig_forest     = forest_figure(scope)

        fig_right = (ppc_purchase_overlay_figure(row)
                     if (tab_right or "waterfall") == "ppc"
                     else waterfall_figure(row, df_tm, seg, mod, loy))

        # 6) ìµœì¢… 15ê°œ ë¦¬í„´(ì½œë°± Output ìˆœì„œëŒ€ë¡œ)
        return (
            kpi_sample_text, buy_s, buy_f,     # kpi-sample, kpi-buy-success, kpi-buy-fail
            ins_final, ins_drop, ins_uncert,   # ì¸ì‚¬ì´íŠ¸ 3ê°œ
            tbl.to_dict("records"),            # metrics-table.data
            fig_sankey, fig_matrix,            # sankey, matrix
            fig_bubble, fig_stage_rank,        # bubble, stage-rank
            fig_survival, fig_right,           # survival, right-panel(waterfall/ppc)
            fig_funnel,                        # funnel
            fig_forest                         # forest
        )

    except Exception:
        print("UPDATE ERROR:\n", traceback.format_exc())
        return (
            "â€“","â€“","â€“","â€“","â€“","â€“",
            [],
            empty, empty, empty, empty, empty, empty, empty, empty
        )

# ===================== ì‹¤í–‰ =====================
if __name__ == "__main__":
    base_port = int(os.getenv("PORT", "8059"))
    for i in range(5):
        try:
            app.run_server(host="0.0.0.0", port=base_port + i, debug=False, use_reloader=False)
            break
        except (OSError, SystemExit) as e:
            if "Address already in use" in str(e) or getattr(e, "code", None) == 1:
                continue
            raise

